
@article{le0,
	title = {Higher order dynamic mode decomposition of noisy experimental data: {The} flow structure of a zero-net-mass-flux jet},
	volume = {88},
	issn = {08941777},
	shorttitle = {Higher order dynamic mode decomposition of noisy experimental data},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S089417771730184X},
	doi = {10.1016/j.expthermflusci.2017.06.011},
	abstract = {A method is presented to treat complex experimental flow data resulting from PIV. The method is based on an appropriate combination of higher order singular value decomposition (which cleans the data along the temporal dimension and the various space dimensions) and higher order dynamic mode decomposition (HODMD), a recent extension of standard dynamic mode decomposition that treats the data in a sliding window. The performance of the method is tested using experimental data obtained in the near field of a zero-net-mass-flux (ZNMF) jet. The better performance of HODMD is put in evidence making this technique suitable to both, cleaning the experimental noise using a limited number of snapshots and obtaining robust and sufficiently accurate results that elucidate the spatio-temporal structure of the flow. The results show that this ZNMF jet is temporally periodic in the near field, where the flow results from the interaction of a large number harmonics. These harmonics involve large scale spatial flow structures, identified as spatially growing instabilities, which are associated with the flow transition to turbulence in the far field.},
	language = {en},
	urldate = {2019-03-06},
	journal = {Experimental Thermal and Fluid Science},
	author = {Le Clainche, Soledad and Vega, Jos{\'e} M. and Soria, Julio},
	month = nov,
	year = {2017},
	pages = {336--353},
}

@article{giannakis1,
	title = {Data-driven spectral decomposition and forecasting of ergodic dynamical systems},
	issn = {10635203},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1063520317300982},
	doi = {10.1016/j.acha.2017.09.001},
	abstract = {We develop a framework for dimension reduction, mode decomposition, and nonparametric forecasting of data generated by ergodic dynamical systems. This framework is based on a representation of the Koopman and Perron{\textendash}Frobenius groups of unitary operators in a smooth orthonormal basis of the L2 space of the dynamical system, acquired from time-ordered data through the diffusion maps algorithm. Using this representation, we compute Koopman eigenfunctions through a regularized advection{\textendash}diffusion operator, and employ these eigenfunctions in dimension reduction maps with projectible dynamics and high smoothness for the given observation modality. In systems with pure point spectra, we construct a decomposition of the generator of the Koopman group into mutually commuting vector fields that transform naturally under changes of observation modality, which we reconstruct in data space through a representation of the pushforward map in the Koopman eigenfunction basis. We also establish a correspondence between Koopman operators and Laplace{\textendash}Beltrami operators constructed from data in Takens delaycoordinate space, and use this correspondence to provide an interpretation of diffusion-mapped delay coordinates for this class of systems. Moreover, we take advantage of a special property of the Koopman eigenfunction basis, namely that the basis elements evolve as simple harmonic oscillators, to build nonparametric forecast models for probability densities and observables. In systems with more complex spectral behavior, including mixing systems, we develop a method inspired from time change in dynamical systems to transform the generator to a new operator with potentially improved spectral properties, and use that operator for vector field decomposition and nonparametric forecasting.},
	language = {en},
	urldate = {2019-03-06},
	journal = {Applied and Computational Harmonic Analysis},
	author = {Giannakis, Dimitrios},
	month = sep,
	year = {2017},
}

@article{champion2,
	title = {Discovery of {Nonlinear} {Multiscale} {Systems}: {Sampling} {Strategies} and {Embeddings}},
	volume = {18},
	issn = {1536-0040},
	shorttitle = {Discovery of {Nonlinear} {Multiscale} {Systems}},
	url = {https://epubs.siam.org/doi/10.1137/18M1188227},
	doi = {10.1137/18M1188227},
	abstract = {A major challenge in the study of dynamical systems is that of model discovery: turning data into models that are not just predictive, but provide insight into the nature of the underlying dynamical system that generated the data. This problem is made more difficult by the fact that many systems of interest exhibit diverse behaviors across multiple time scales. We introduce a number of datadriven strategies for discovering nonlinear multiscale dynamical systems and their embeddings from data. We consider two canonical cases: (i) systems for which we have full measurements of the governing variables and (ii) systems for which we have incomplete measurements. For systems with full state measurements, we show that the recent sparse identification of nonlinear dynamical systems (SINDy) method can discover governing equations with relatively little data, provided that accurate measurements of the derivatives can be computed from the data. We introduce a sampling method that allows SINDy to scale efficiently to problems with multiple time scales; specifically, we can discover distinct governing equations at slow and fast scales. For systems with incomplete observations, we show that the Hankel alternative view of Koopman (HAVOK) method, based on time-delay embedding coordinates, can be used to obtain a linear model and Koopman invariant measurement system that nearly perfectly captures the dynamics of nonlinear quasiperiodic systems on the attractor. We introduce two strategies for using HAVOK on systems with multiple time scales. Together, our approaches provide a suite of mathematical strategies for reducing the data required to discover and model nonlinear multiscale systems.},
	language = {en},
	number = {1},
	urldate = {2019-03-06},
	journal = {SIAM Journal on Applied Dynamical Systems},
	author = {Champion, Kathleen P. and Brunton, Steven L. and Kutz, J. Nathan},
	month = jan,
	year = {2019},
	pages = {312--333},
}

@article{tu3,
	title = {On {Dynamic} {Mode} {Decomposition}: {Theory} and {Applications}},
	volume = {1},
	issn = {2158-2491},
	shorttitle = {On {Dynamic} {Mode} {Decomposition}},
	url = {http://arxiv.org/abs/1312.0041},
	doi = {10.3934/jcd.2014.1.391},
	abstract = {Originally introduced in the fluid mechanics community, dynamic mode decomposition (DMD) has emerged as a powerful tool for analyzing the dynamics of nonlinear systems. However, existing DMD theory deals primarily with sequential time series for which the measurement dimension is much larger than the number of measurements taken. We present a theoretical framework in which we define DMD as the eigendecomposition of an approximating linear operator. This generalizes DMD to a larger class of datasets, including nonsequential time series. We demonstrate the utility of this approach by presenting novel sampling strategies that increase computational efficiency and mitigate the effects of noise, respectively. We also introduce the concept of linear consistency, which helps explain the potential pitfalls of applying DMD to rank-deficient datasets, illustrating with examples. Such computations are not considered in the existing literature, but can be understood using our more general framework. In addition, we show that our theory strengthens the connections between DMD and Koopman operator theory. It also establishes connections between DMD and other techniques, including the eigensystem realization algorithm (ERA), a system identification method, and linear inverse modeling (LIM), a method from climate science. We show that under certain conditions, DMD is equivalent to LIM.},
	language = {en},
	number = {2},
	urldate = {2019-03-06},
	journal = {Journal of Computational Dynamics},
	author = {Tu, Jonathan H. and Rowley, Clarence W. and Luchtenburg, Dirk M. and Brunton, Steven L. and Kutz, J. Nathan},
	month = dec,
	year = {2014},
	note = {arXiv: 1312.0041},
	keywords = {koopman},
	pages = {391--421},
}

@article{williams4,
	title = {A {Data}{\textendash}{Driven} {Approximation} of the {Koopman} {Operator}: {Extending} {Dynamic} {Mode} {Decomposition}},
	volume = {25},
	issn = {0938-8974, 1432-1467},
	shorttitle = {A {Data}{\textendash}{Driven} {Approximation} of the {Koopman} {Operator}},
	url = {http://link.springer.com/10.1007/s00332-015-9258-5},
	doi = {10.1007/s00332-015-9258-5},
	language = {en},
	number = {6},
	urldate = {2019-03-13},
	journal = {Journal of Nonlinear Science},
	author = {Williams, Matthew O. and Kevrekidis, Ioannis G. and Rowley, Clarence W.},
	month = dec,
	year = {2015},
	pages = {1307--1346},
}

@inproceedings{rabin6,
	title = {Heterogeneous datasets representation and learning using diffusion maps and {Laplacian} pyramids},
	isbn = {978-1-61197-232-0 978-1-61197-282-5},
	url = {https://epubs.siam.org/doi/10.1137/1.9781611972825.17},
	doi = {10.1137/1.9781611972825.17},
	abstract = {The diffusion maps together with the geometric harmonics provide a method for describing the geometry of high dimensional data and for extending these descriptions to new data points and to functions, which are defined on the data. This method suffers from two limitations. First, even though real-life data is often heterogeneous , the assumption in diffusion maps is that the attributes of the processed dataset are comparable. Second, application of the geometric harmonics requires careful setting for the correct extension scale and condition number. In this paper, we propose a method for representing and learning heterogeneous datasets by using diffusion maps for unifying and embedding heterogeneous dataset and by replacing the geometric harmonics with the Laplacian pyramid extension. Experimental results on three benchmark datasets demonstrate how the learning process becomes straightforward when the constructed representation smoothly parameterizes the task-related function.},
	language = {en},
	urldate = {2019-12-14},
	booktitle = {Proceedings of the 2012 {SIAM} {International} {Conference} on {Data} {Mining}},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Rabin, Neta and Coifman, Ronald R.},
	month = apr,
	year = {2012},
	pages = {189--199},
}

@article{coifman7,
	title = {Geometric harmonics: {A} novel tool for multiscale out-of-sample extension of empirical functions},
	volume = {21},
	issn = {10635203},
	shorttitle = {Geometric harmonics},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1063520306000522},
	doi = {10.1016/j.acha.2005.07.005},
	abstract = {We describe a simple scheme, based on the Nystr{\"o}m method, for extending empirical functions f defined on a set X to a larger set X{\textasciimacron} . The extension process that we describe involves the construction of a specific family of functions that we term geometric harmonics. These functions constitute a generalization of the prolate spheroidal wave functions of Slepian in the sense that they are optimally concentrated on X. We study the case when X is a submanifold of Rn in greater detail. In this situation, any empirical function f on X can be characterized by its decomposition over the intrinsic Fourier modes, i.e., the eigenfunctions of the Laplace{\textendash}Beltrami operator, and we show that this intrinsic frequency spectrum determines the largest domain of extension of f to the entire space Rn. Our analysis relates the complexity of the function on the training set to the scale of extension off this set. This approach allows us to present a novel multiscale extension scheme for empirical functions.},
	language = {en},
	number = {1},
	urldate = {2019-12-15},
	journal = {Applied and Computational Harmonic Analysis},
	author = {Coifman, Ronald R. and Lafon, St{\'e}phane},
	month = jul,
	year = {2006},
	pages = {31--52},
}

@article{coifman8,
	title = {Diffusion maps},
	volume = {21},
	issn = {10635203},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1063520306000546},
	doi = {10.1016/j.acha.2006.04.006},
	abstract = {In this paper, we provide a framework based upon diffusion processes for finding meaningful geometric descriptions of data sets. We show that eigenfunctions of Markov matrices can be used to construct coordinates called diffusion maps that generate efficient representations of complex geometric structures. The associated family of diffusion distances, obtained by iterating the Markov matrix, defines multiscale geometries that prove to be useful in the context of data parametrization and dimensionality reduction. The proposed framework relates the spectral properties of Markov processes to their geometric counterparts and it unifies ideas arising in a variety of contexts such as machine learning, spectral graph theory and eigenmap methods.},
	language = {en},
	number = {1},
	urldate = {2019-12-15},
	journal = {Applied and Computational Harmonic Analysis},
	author = {Coifman, Ronald R. and Lafon, St{\'e}phane},
	month = jul,
	year = {2006},
	pages = {5--30},
}

@article{bengio9,
	title = {Learning {Eigenfunctions} {Links} {Spectral} {Embedding} and {Kernel} {PCA}},
	volume = {16},
	issn = {0899-7667, 1530-888X},
	url = {http://www.mitpressjournals.org/doi/10.1162/0899766041732396},
	doi = {10.1162/0899766041732396},
	abstract = {In this paper, we show a direct relation between spectral embedding methods and kernel PCA, and how both are special cases of a more general learning problem, that of learning the principal eigenfunctions of an operator defined from a kernel and the unknown data generating density.},
	language = {en},
	number = {10},
	urldate = {2019-12-15},
	journal = {Neural Computation},
	author = {Bengio, Yoshua and Delalleau, Olivier and Roux, Nicolas Le and Paiement, Jean-Fran{\c c}ois and Vincent, Pascal and Ouimet, Marie},
	month = oct,
	year = {2004},
	pages = {2197--2219},
}

@article{fernandez10,
	title = {Auto-adaptative {Laplacian} {Pyramids} for {High}-dimensional {Data} {Analysis}},
	url = {http://arxiv.org/abs/1311.6594},
	abstract = {Non-linear dimensionality reduction techniques such as manifold learning algorithms have become a common way for processing and analyzing high-dimensional patterns that often have attached a target that corresponds to the value of an unknown function. Their application to new points consists in two steps: first, embedding the new data point into the low dimensional space and then, estimating the function value on the test point from its neighbors in the embedded space.},
	language = {en},
	urldate = {2019-12-22},
	journal = {arXiv:1311.6594 [cs, stat]},
	author = {Fern{\'a}ndez, {\'A}ngela and Rabin, Neta and Fishelov, Dalia and Dorronsoro, Jos{\'e} R.},
	month = may,
	year = {2014},
	note = {arXiv: 1311.6594},
}

@article{li11,
	title = {Extended dynamic mode decomposition with dictionary learning: a data-driven adaptive spectral decomposition of the {Koopman} operator},
	volume = {27},
	issn = {1054-1500, 1089-7682},
	shorttitle = {Extended dynamic mode decomposition with dictionary learning},
	url = {http://arxiv.org/abs/1707.00225},
	doi = {10.1063/1.4993854},
	abstract = {Numerical approximation methods for the Koopman operator have advanced considerably in the last few years. In particular, data-driven approaches such as dynamic mode decomposition (DMD) and its generalization, the extended-DMD (EDMD), are becoming increasingly popular in practical applications. The EDMD improves upon the classical DMD by the inclusion of a flexible choice of dictionary of observables that spans a finite dimensional subspace on which the Koopman operator can be approximated. This enhances the accuracy of the solution reconstruction and broadens the applicability of the Koopman formalism. Although the convergence of the EDMD has been established, applying the method in practice requires a careful choice of the observables to improve convergence with just a finite number of terms. This is especially difficult for high dimensional and highly nonlinear systems. In this paper, we employ ideas from machine learning to improve upon the EDMD method. We develop an iterative approximation algorithm which couples the EDMD with a trainable dictionary represented by an artificial neural network. Using the Duffing oscillator and the Kuramoto Sivashinsky PDE as examples, we show that our algorithm can effectively and efficiently adapt the trainable dictionary to the problem at hand to achieve good reconstruction accuracy without the need to choose a fixed dictionary a priori. Furthermore, to obtain a given accuracy we require fewer dictionary terms than EDMD with fixed dictionaries. This alleviates an important shortcoming of the EDMD algorithm and enhances the applicability of the Koopman framework to practical problems.},
	language = {en},
	number = {10},
	urldate = {2020-01-06},
	journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
	author = {Li, Qianxiao and Dietrich, Felix and Bollt, Erik M. and Kevrekidis, Ioannis G.},
	month = oct,
	year = {2017},
	note = {arXiv: 1707.00225},
	pages = {103111},
}

@book{kutz12,
	title = {Dynamic mode decomposition. {Data}-{Driven} modelling of complex systems},
	isbn = {978-1-61197-450-8},
	language = {en},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Kutz, J. Nathan and Brunton, Steven L. and Brunton, Bingni W. and Proctor, Joshua L.},
	year = {2016},
}

@article{schmid13,
	title = {Dynamic mode decomposition of numerical and experimental data},
	volume = {656},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/product/identifier/S0022112010001217/type/journal_article},
	doi = {10.1017/S0022112010001217},
	abstract = {The description of coherent features of fluid flow is essential to our understanding of fluid-dynamical and transport processes. A method is introduced that is able to extract dynamic information from flow fields that are either generated by a (direct) numerical simulation or visualized/measured in a physical experiment. The extracted dynamic modes, which can be interpreted as a generalization of global stability modes, can be used to describe the underlying physical mechanisms captured in the data sequence or to project large-scale problems onto a dynamical system of significantly fewer degrees of freedom. The concentration on subdomains of the flow field where relevant dynamics is expected allows the dissection of a complex flow into regions of localized instability phenomena and further illustrates the flexibility of the method, as does the description of the dynamics within a spatial framework. Demonstrations of the method are presented consisting of a plane channel flow, flow over a two-dimensional cavity, wake flow behind a flexible membrane and a jet passing between two cylinders.},
	language = {en},
	urldate = {2020-04-09},
	journal = {Journal of Fluid Mechanics},
	author = {Schmid, Peter J.},
	month = aug,
	year = {2010},
	pages = {5--28},
}

@article{belkin14,
	title = {Laplacian {Eigenmaps} for {Dimensionality} {Reduction} and {Data} {Representation}},
	volume = {15},
	issn = {0899-7667, 1530-888X},
	url = {http://www.mitpressjournals.org/doi/10.1162/089976603321780317},
	doi = {10.1162/089976603321780317},
	language = {en},
	number = {6},
	urldate = {2020-04-29},
	journal = {Neural Computation},
	author = {Belkin, Mikhail and Niyogi, Partha},
	month = jun,
	year = {2003},
	pages = {1373--1396},
}

@article{donoho15,
	title = {Hessian eigenmaps: {Locally} linear embedding techniques for high-dimensional data},
	volume = {100},
	issn = {0027-8424, 1091-6490},
	shorttitle = {Hessian eigenmaps},
	url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1031596100},
	doi = {10.1073/pnas.1031596100},
	language = {en},
	number = {10},
	urldate = {2020-04-29},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Donoho, D. L. and Grimes, C.},
	month = may,
	year = {2003},
	pages = {5591--5596},
}

@book{bishop16,
	address = {New York},
	series = {Information science and statistics},
	title = {Pattern recognition and machine learning},
	isbn = {978-0-387-31073-2},
	language = {en},
	publisher = {Springer},
	author = {Bishop, Christopher M.},
	year = {2006},
	keywords = {Machine learning, Pattern perception},
}

@article{pedregosa17,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
	abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
	language = {en},
	journal = {MACHINE LEARNING IN PYTHON},
	author = {Pedregosa, Fabian and Varoquaux, Gael and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David},
	year = {2011},
	pages = {6},
}

@article{brunton18,
	title = {Discovering governing equations from data by sparse identification of nonlinear dynamical systems},
	volume = {113},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1517384113},
	doi = {10.1073/pnas.1517384113},
	abstract = {Extracting governing equations from data is a central challenge in many diverse areas of science and engineering. Data are abundant whereas models often remain elusive, as in climate science, neuroscience, ecology, finance, and epidemiology, to name only a few examples. In this work, we combine sparsity-promoting techniques and machine learning with nonlinear dynamical systems to discover governing equations from noisy measurement data. The only assumption about the structure of the model is that there are only a few important terms that govern the dynamics, so that the equations are sparse in the space of possible functions; this assumption holds for many physical systems in an appropriate basis. In particular, we use sparse regression to determine the fewest terms in the dynamic governing equations required to accurately represent the data. This results in parsimonious models that balance accuracy with model complexity to avoid overfitting. We demonstrate the algorithm on a wide range of problems, from simple canonical systems, including linear and nonlinear oscillators and the chaotic Lorenz system, to the fluid vortex shedding behind an obstacle. The fluid example illustrates the ability of this method to discover the underlying dynamics of a system that took experts in the community nearly 30 years to resolve. We also show that this method generalizes to parameterized systems and systems that are time-varying or have external forcing.},
	language = {en},
	number = {15},
	urldate = {2020-04-29},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Brunton, Steven L. and Proctor, Joshua L. and Kutz, J. Nathan},
	month = apr,
	year = {2016},
	pages = {3932--3937},
}
