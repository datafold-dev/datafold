{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Dynamic Mode Decomposition on Limit Cycle\n",
    "\n",
    "In this tutorial we explore the (Extended-) Dynamic Mode Decomposition (E-DMD). We set up a non-linear ordinary differential equation (ODE) system, generate time series data with it and learn the dynamics with an `EDMD` model. \n",
    "\n",
    "Note that all models for time series modelling require `TSCDataFrame` type for fitting (`.fit`). The initial conditions for `predict` can be either `numpy.ndarray` or `pandas.DataFrame` typed (as long as the initial condition itself is not a time series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "# NOTE: make sure \"path/to/datafold\" is in sys.path or PYTHONPATH if not installed\n",
    "from datafold.pcfold import TSCDataFrame, GaussianKernel\n",
    "from datafold.dynfold import DMDFull\n",
    "from datafold.dynfold.transform import TSCRadialBasis, TSCPolynomialFeatures\n",
    "from datafold.appfold import EDMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up ODE system\n",
    "\n",
    "We set up a Hopf ODE system with:\n",
    "\n",
    "$$\n",
    "\\dot{y}_0 = -y_1 + y_0 (\\mu - y_0^2 - y_1^2) \\\\\n",
    "\\dot{y}_1 = y_0 + y_1 (\\mu - y_0^2 - y_1^2)\n",
    "$$\n",
    "\n",
    "with $\\mu=1$. The ODE system has an circle shaped attractor which is centered at the origin. All sampled initial conditions are off the attractor (i.e. the time series are sampled on the transient phase space region). \n",
    "\n",
    "We solve the system by integration (Runge Kutta 45) with scipy's ODE solver. The return type is `TSCDataFrame` and includes a time series for each initial condition (row in `initial_conditions`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_limit_cycle(initial_conditions, t_eval):\n",
    "    \n",
    "    def limit_cycle(t, y):\n",
    "        \"\"\"ODE system.\"\"\"\n",
    "        mu = 1\n",
    "        y_dot = np.zeros(2)\n",
    "\n",
    "        factor = mu - y[0] ** 2 - y[1] ** 2\n",
    "\n",
    "        y_dot[0] = -y[1] + y[0] * factor\n",
    "        y_dot[1] = y[0] + y[1] * factor\n",
    "        return y_dot\n",
    "\n",
    "    assert initial_conditions.ndim == 2\n",
    "    assert initial_conditions.shape[1] == 2\n",
    "\n",
    "    time_series_dfs = []\n",
    "\n",
    "    for ic in initial_conditions:\n",
    "        solution = solve_ivp(limit_cycle, t_span=(t_eval[0], t_eval[-1]), y0=ic, t_eval=t_eval)\n",
    "        \n",
    "        solution = pd.DataFrame(\n",
    "            data=solution[\"y\"].T,\n",
    "            index=solution[\"t\"],\n",
    "            columns=[\"x1\", \"x2\"],\n",
    "        )\n",
    "\n",
    "        time_series_dfs.append(solution)\n",
    "\n",
    "    return TSCDataFrame.from_frame_list(time_series_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling the dynamical system\n",
    "\n",
    "We now start collecting time series data from the ODE system (our training set). To sample the phase space, we distribute initial conditions and solve the ODE system for rather short time intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_time_steps = 30\n",
    "t_eval = np.linspace(0, 0.4, 20)\n",
    "\n",
    "initial_conditions = np.array(np.meshgrid(np.linspace(-2, 2, 8), np.linspace(-2, 2, 8))).T.reshape(-1, 2)\n",
    "\n",
    "tsc_data = solve_limit_cycle(initial_conditions, t_eval)\n",
    "\n",
    "print(f\"time delta: {tsc_data.delta_time}\")\n",
    "print(f\"#time series: {tsc_data.n_timeseries}\")\n",
    "print(f\"#time steps per time series: {tsc_data.n_timesteps}\")\n",
    "print(f\"(n_samples, n_features): {tsc_data.shape}\")\n",
    "print(f\"time interval {tsc_data.time_interval()}\")\n",
    "print(f\"Same time values: {tsc_data.is_same_time_values()} \")\n",
    "print(\"\")\n",
    "print(\"Data snippet:\")\n",
    "tsc_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot: Sampled time series used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to add a single arrow in the following time series plots\n",
    "idx_arrow = np.array([t_eval.shape[0] // 2 -1, t_eval.shape[0] // 2])\n",
    "\n",
    "def include_arrow(ax, df):\n",
    "    arrow = df.iloc[idx_arrow, :]\n",
    "    ax.arrow(arrow.iloc[0, 0], \n",
    "             arrow.iloc[0, 1], \n",
    "             dx=arrow.iloc[1, 0]-arrow.iloc[0, 0], \n",
    "             dy=arrow.iloc[1, 1]-arrow.iloc[0, 1], \n",
    "             color=\"black\", head_width=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[7,7])\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "for _id, df in tsc_data.itertimeseries():\n",
    "    ax.plot(df[\"x1\"].to_numpy(), df[\"x2\"].to_numpy(), 0.1, c=\"black\")\n",
    "    include_arrow(ax, df)\n",
    "\n",
    "ax.set_title(\"sampled time series data from ODE system\")\n",
    "ax.set_xlabel(\"x1\")\n",
    "ax.set_ylabel(\"x2\")\n",
    "ax.axis(\"equal\")\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DMD: Identity dictionary\n",
    "\n",
    "In our first model we use a Dynamic Mode Decomposition (in `datafold.dynfold.dmd`) model and decompose the data in spatio-temporal coordinates using the original form of the time series. In other words, our dictionary only includes the state identities \"x1\" and \"x2\" as observable functions. \n",
    "\n",
    "We use the `DMDFull` model directly (the same can be accomblished with `EDMD` and setting `dict_step=[\"id\", TSCIdentity()]`).\n",
    "\n",
    "Note that the DMD-based models' API aligns with scikit-learn. However, the input type of `X` is restricted to a `TSCDataFrame`. The `predict` method allows to set an array of `time_values`, where we can choose at which time samples to evaluate the model. In this case, when we are interested in reconstructing the training data, we leave it as `None`. The model then uses the same time values that were available during `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmd = DMDFull().fit(X=tsc_data)  # must be TSCDataFrame\n",
    "dmd_values = dmd.predict(tsc_data.initial_states(), time_values=None)\n",
    "\n",
    "print(\"Data snipped with predicted time series data\")\n",
    "dmd_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with training data \n",
    "\n",
    "We can now visually compare the original time series data with the data-driven reconstruction of the DMD model. The plots show us that the DMD model performs relatively poor. The Koopman matrix, which describes a linear dynamical system is only a $\\mathbb{R}^{2 \\times 2}$ matrix. We can therefore classify the phase portrait with [stability theory](https://en.wikipedia.org/wiki/Stability_theory). Note that the Koopman matrix internally describes a dicrete system with fixed time interval. We therefore have have to first convert the Koopman matrix to its continuous form.\n",
    "\n",
    "#### TODO: the stability analysis is not right... The solution should be a sink source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_koopman_matrix = np.log(dmd.koopman_matrix_.astype(np.complex)) / dmd.dt_\n",
    "\n",
    "print(\"Relevant values for stability analysis:\")\n",
    "print(f\"determinant {np.linalg.det(cont_koopman_matrix)}\")\n",
    "print(f\"trace {np.trace(cont_koopman_matrix)}\")\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "for _id, df in tsc_data.itertimeseries():\n",
    "    ax[0].plot(df[\"x1\"].to_numpy(), df[\"x2\"].to_numpy(), 0.1, c=\"black\")\n",
    "    include_arrow(ax[0], df)\n",
    "\n",
    "ax[0].set_title(\"training data used during fit\")\n",
    "ax[0].set_xlabel(\"x1\")\n",
    "ax[0].set_ylabel(\"x2\")\n",
    "ax[0].axis(\"equal\")\n",
    "ax[0].grid()\n",
    "\n",
    "for _id, df in dmd_values.itertimeseries():\n",
    "    ax[1].plot(df[\"x1\"].to_numpy(), df[\"x2\"].to_numpy(), 0.1, c=\"black\")\n",
    "    include_arrow(ax[1], df)\n",
    "    \n",
    "ax[1].set_title(\"DMD model (identity state dictionary)\")\n",
    "ax[1].set_xlabel(\"x1\")\n",
    "ax[1].set_ylabel(\"x2\")\n",
    "ax[1].axis(\"equal\")\n",
    "ax[1].grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDMD: Polynomial feature dictionary\n",
    "\n",
    "We now get to the \"extended\" part of a Dynamic Model Decomposition: We define a *dictionary* in which we process the time series data before we fit a DMD model with it. For this, we use the `datafold.appfold.EDMD` class, which is a [`sklearn.pipeline.Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html?highlight=pipeline#sklearn.pipeline.Pipeline). In the `EDMD` model, a dictionary can be a variable number of transform models that are process the time series data consecutively (in same order as defined). The final final estimator has to be a `datafold.dynfold.dmd.DMDBase` model and defaults to `DMDFull`.  \n",
    "\n",
    "Choosing the \"right\" dictionary is not an easy task and is similar to \"model selection\" in classical machine learning. In our choice of dictionary we can include expert knowledge, e.g. if we know the principle equations from an underlying physical system from which time series are collected. We can also apply methods from mathematical theory to represent the data in another (functional) basis with the aim to linearize an unknown phase space's manifold. \n",
    "\n",
    "In the first dictionary we use `TSCPolynomialFeatures` which is a wrapper of [`sklearn.preprocessing.PolynomialFeatures`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html?highlight=polynomial#sklearn.preprocessing.PolynomialFeatures) to support `TSCDataFrame` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_step = [\n",
    "    (\n",
    "        \"polynomial\",\n",
    "        TSCPolynomialFeatures(degree=3),\n",
    "    )\n",
    "]\n",
    "\n",
    "edmd_poly = EDMD(dict_steps=dict_step, include_id_state=True).fit(X=tsc_data)\n",
    "edmd_poly_values = edmd_poly.predict(tsc_data.initial_states())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the dictionary\n",
    "\n",
    "Before we compare the model's time series data to the training data, we investigate how we to analyze the actual process of dictionary transformations in a `EDMD` model.  \n",
    "\n",
    "For example, we may be interested in the values of the \"dictionary space\" (the data after all the transformations are applied before it in handled to the final DMD model). For this we can use the `transform` method of `EDMD` which applies the dictionary on the available data (e.g. our training set). In this case we can see that the result is a `TSCDataFrame` which includes the original states \"x1\" and \"x2\" plus the generated polynomial features. \n",
    "\n",
    "The single dictionary models are accessible with the specified name via `named_steps`. Here, we access the model and its attribute `TSCPolynomialFeatures.powers_` through the `EDMD` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access models in the dictionary, the name was given in \"dict_step\" above \n",
    "print(edmd_poly.named_steps[\"polynomial\"])\n",
    "\n",
    "print(\"\")\n",
    "print(\"polynomial degrees for data (first column 'x1' and second 'x2'):\")\n",
    "print(edmd_poly.named_steps[\"polynomial\"].powers_)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Dictionary space values:\")\n",
    "edmd_poly.transform(tsc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with training data\n",
    "\n",
    "We see that reconstruction of time series improved and the phase portrait now look a lot better than the previous DMD approach. However, there are still differences and some time series even cross, which is not a behavior of the original system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "for _id, df in tsc_data.itertimeseries():\n",
    "    ax[0].plot(df[\"x1\"].to_numpy(), df[\"x2\"].to_numpy(), 0.1, c=\"black\")\n",
    "    include_arrow(ax[0], df)\n",
    "\n",
    "ax[0].set_title(\"training data used during fit\")\n",
    "ax[0].set_xlabel(\"x1\")\n",
    "ax[0].set_ylabel(\"x2\")\n",
    "ax[0].axis(\"equal\");\n",
    "\n",
    "for _id, df in edmd_poly_values.itertimeseries():\n",
    "    ax[1].plot(df[\"x1\"].to_numpy(), df[\"x2\"].to_numpy(), 0.1, c=\"black\")\n",
    "    include_arrow(ax[1], df)\n",
    "    \n",
    "ax[1].set_title(\"EDMD with polyomial dictionary\")\n",
    "ax[1].set_xlabel(\"x1\")\n",
    "ax[1].set_ylabel(\"x2\")\n",
    "ax[1].axis(\"equal\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDMD: Radial basis function dictionary\n",
    "\n",
    "In our last attempt we set up a dictionary with `TSCRadialBasis`. The transform class computes coefficients of each time series sample to a set of basis functions (which are distributed in the phase space). The radial basis functions therefore provide a way to linearize the phase space's manifold. Here we choose a Gaussian kernel and set the center of the functions to the initial condition states.\n",
    "\n",
    "In the time series in \"dictionary space\" we see that the feature dimension is now much greater than in the beginning (i.e. we provide a larger set of observables to compute the Koopman operator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_step = [(\"rbf\", TSCRadialBasis(kernel=GaussianKernel(epsilon=0.17), center_type=\"initial_condition\"))]\n",
    "\n",
    "edmd_rbf = EDMD(dict_steps=dict_step, include_id_state=True).fit(X=tsc_data)  # Note that the \"extended\" part is in the transformations\n",
    "edmd_rbf_values = edmd_rbf.predict(tsc_data.initial_states())\n",
    "\n",
    "print(f\"shape of Koopman matrix: {edmd_rbf.named_steps['dmd'].koopman_matrix_.shape}\")\n",
    "edmd_rbf.transform(tsc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with training data\n",
    "\n",
    "Again for comparison we plot the training time series next to the EDMD model's time series. This time the phase portraits match quite well. However, at this stage this is only an indicator of a successful model. Like for all data-driven machine learning models there is always the danger to overfit the training data. The consequence is a poor generalization for out-of-sample initial conditions. \n",
    "\n",
    "The right way to tackle overfitting is to apply cross-validation. For the `EDMD` model this can be achieved with `EDMDCV`, which allows an exhausitve search over a grid of the model's and the dictionary model parameters. **datafold** provides time series splitting for cross validation which enables measureing the model's quality on unseen (partial) time series data.\n",
    "\n",
    "For this tutorial, we only add a single out-of-sample initial condition and compare it to the ODE system. We used this plot to visually \"optimize\" the Gaussian kernel epilon value. If we now predict the time series we want to highlight that the `EDMD` model interpolates in time. This means, we are now able to freely choose the time interval and number of time samples at which to evaluate the model. In the time series we can see that the model follows the ground truth solution fairly well for some time. However, the `EDMD` model won't stay on the attractor for $t \\rightarrow \\infty$ yet.\n",
    "\n",
    "The problem of overfitting can be seen if `epsilon=1` is set in the Gaussian kernel. The reconstruction phase portrait looks equally well, but the out-of-sample quality decreases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, sharey=True, figsize=(14, 5))\n",
    "for _id, df in tsc_data.itertimeseries():\n",
    "    ax[0].plot(df[\"x1\"].to_numpy(), df[\"x2\"].to_numpy(), 0.1, c=\"black\")\n",
    "    include_arrow(ax[0], df)\n",
    "    \n",
    "ax[0].set_title(\"training data used during fit\")\n",
    "ax[0].set_xlabel(\"x1\")\n",
    "ax[0].set_ylabel(\"x2\")\n",
    "ax[0].axis(\"equal\");\n",
    "ax[0].grid()\n",
    "\n",
    "for _id, df in edmd_rbf_values.itertimeseries():\n",
    "    ax[1].plot(df[\"x1\"].to_numpy(), df[\"x2\"].to_numpy(), 0.1, c=\"black\")\n",
    "    include_arrow(ax[1], df)\n",
    "\n",
    "ax[1].set_title(\"EDMD with RBF dictionary\")\n",
    "ax[1].set_xlabel(\"x1\")\n",
    "ax[1].set_ylabel(\"x2\")\n",
    "ax[1].axis(\"equal\")\n",
    "ax[1].grid()\n",
    "\n",
    "\n",
    "# make out-of-sample prediction\n",
    "initial_condition = np.array([[2, 1]])\n",
    "t_eval = np.linspace(0, 7, 400)\n",
    "\n",
    "ground_truth = solve_limit_cycle(initial_condition, t_eval)\n",
    "predicted = edmd_rbf.predict(initial_condition, t_eval)\n",
    "\n",
    "f, ax = plt.subplots(figsize=(7,7))\n",
    "\n",
    "ax.plot(ground_truth.loc[:, \"x1\"], ground_truth.loc[:, \"x2\"], label=\"true system\")\n",
    "include_arrow(ax, ground_truth)\n",
    "ax.plot(predicted.loc[:, \"x1\"], predicted.loc[:, \"x2\"], c=\"orange\", label=\"edmd_rbf\")\n",
    "\n",
    "ax.set_title(\"out-of-sample prediction\")\n",
    "ax.axis(\"equal\")\n",
    "ax.grid()\n",
    "ax.legend();\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
