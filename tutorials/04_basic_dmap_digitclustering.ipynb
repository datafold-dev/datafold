{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Visit the\n",
    "[documentation](https://datafold-dev.gitlab.io/datafold/tutorial_index.html) page\n",
    "to view the executed notebook.)\n",
    "\n",
    "# Manifold learning on handwritten digits\n",
    "\n",
    "Disclaimer: Code parts are taken from [scikit-learn: Manifold learning on handwritten digits](https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html). \n",
    "\n",
    "Based on the scikit-learn comparison of manifold learning models, we add the `DiffusionMaps` algorithm. We will also show the additional functionality of embedding unseen points (out-of-sampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import offsetbox\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datafold.pcfold as pfold\n",
    "from datafold.dynfold import DiffusionMaps\n",
    "from datafold.utils.plot import plot_pairwise_eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source code taken and adapted from https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html\n",
    "\n",
    "\n",
    "def plot_embedding(X, y, digits, title=None):\n",
    "    \"\"\"Scale and visualize the embedding vectors\"\"\"\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "\n",
    "    plt.figure(figsize=[10, 10])\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        plt.text(\n",
    "            X[i, 0],\n",
    "            X[i, 1],\n",
    "            str(y[i]),\n",
    "            color=plt.cm.Set1(y[i] / 10.0),\n",
    "            fontdict={\"weight\": \"bold\", \"size\": 9},\n",
    "        )\n",
    "\n",
    "    if hasattr(offsetbox, \"AnnotationBbox\"):\n",
    "        # only print thumbnails with matplotlib > 1.0\n",
    "        shown_images = np.array([[1.0, 1.0]])  # just something big\n",
    "        for i in range(X.shape[0]):\n",
    "            dist = np.sum((X[i] - shown_images) ** 2, 1)\n",
    "            if np.min(dist) < 4e-3:\n",
    "                # don't show points that are too close\n",
    "                continue\n",
    "            shown_images = np.r_[shown_images, [X[i]]]\n",
    "            imagebox = offsetbox.AnnotationBbox(\n",
    "                offsetbox.OffsetImage(digits[i], cmap=plt.cm.gray_r), X[i]\n",
    "            )\n",
    "            ax.add_artist(imagebox)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate point cloud of handwritten digits\n",
    "\n",
    "First, we create the handwritten digits from the scikit-learn dataset (only numbers 0-5 as in the comparison). For the separate analysis of out-of-sample embeddings, we also split the dataset in separate a training and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits(n_class=6)\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "images = digits.images\n",
    "\n",
    "X_train, X_test, y_train, y_test, images_train, images_test = train_test_split(\n",
    "    X, y, images, train_size=2 / 3, test_size=1 / 3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diffusion map embedding on the entire dataset\n",
    "\n",
    "We first carry out the same steps from the scikit-learn [comparison](https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html) and embed the entire available dataset. We optimize the parameters `epsilon` and `cut_off` using `PCManifold` (which uses the default `GaussianKernel`). These steps are optional, and the data `X` could have also just fitted directly with a user choice of `epsilon`.\n",
    "\n",
    "We choose the eigenvector coordinates $\\psi_1$ and $\\psi_2$, which are the first two non-trivial eigenvectors (the first eigenvector is constant with eigenvalue $\\lambda=1$). Note that the timings do not directly compare to the timings stated at the comparison webpage as it is executed on different hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pcm = pfold.PCManifold(X)\n",
    "X_pcm.optimize_parameters(result_scaling=2)\n",
    "\n",
    "print(f\"epsilon={X_pcm.kernel.epsilon}, cut-off={X_pcm.cut_off}\")\n",
    "\n",
    "t0 = time.time()\n",
    "dmap = DiffusionMaps(\n",
    "    kernel=pfold.GaussianKernel(epsilon=X_pcm.kernel.epsilon),\n",
    "    n_eigenpairs=6,\n",
    "    dist_kwargs=dict(cut_off=X_pcm.cut_off),\n",
    ")\n",
    "\n",
    "dmap = dmap.fit(X_pcm)\n",
    "dmap = dmap.set_target_coords([1, 2])\n",
    "X_dmap = dmap.transform(X_pcm)\n",
    "\n",
    "# Mapping of diffusion maps\n",
    "plot_embedding(\n",
    "    X_dmap,\n",
    "    y,\n",
    "    images,\n",
    "    title=\"Diffusion map embedding of the digits (time %.2fs)\" % (time.time() - t0),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare different embeddings\n",
    "\n",
    "It may not always be the best choice to use the first two non-trivial eigenvectors (cf. functional dependence between eigenvectors). We can compare different embeddings by plotting $\\psi_1$ versus $\\psi_2$ : $\\psi_5$ (using a `datafold.utils` function from *datafold*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmap = DiffusionMaps(\n",
    "    kernel=pfold.GaussianKernel(epsilon=X_pcm.kernel.epsilon),\n",
    "    n_eigenpairs=6,\n",
    "    dist_kwargs=dict(cut_off=X_pcm.cut_off),\n",
    ")\n",
    "dmap = dmap.fit(X_pcm)\n",
    "plot_pairwise_eigenvector(\n",
    "    eigenvectors=dmap.eigenvectors_[:, 1:],\n",
    "    n=0,\n",
    "    idx_start=1,\n",
    "    fig_params=dict(figsize=(10, 10)),\n",
    "    scatter_params=dict(c=y),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-sample embedding \n",
    "\n",
    "We add another analysis to highlight the out-of-sample functionality of `DiffusionMaps`. We then only use the training data set to fit the model. Afterwards, we carry out the embedding for both the training and test set and visually compare, if the out-of-sample points are mapped to the same regions as the training set. \n",
    "\n",
    "**Note:**\n",
    "Because this is in the context of unsupervised learning, we cannot easily measure an error. There are strategies such as interpreting the embedding as a classification task, but this is out of scope for this tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pcm_train = pfold.PCManifold(X_train)\n",
    "X_pcm_train.optimize_parameters(result_scaling=2)\n",
    "print(f\"epsilon={X_pcm_train.kernel.epsilon}, cut-off={X_pcm_train.cut_off}\")\n",
    "\n",
    "dmap = DiffusionMaps(\n",
    "    kernel=pfold.GaussianKernel(epsilon=X_pcm_train.kernel.epsilon),\n",
    "    n_eigenpairs=6,\n",
    "    dist_kwargs=dict(cut_off=X_pcm_train.cut_off),\n",
    ")\n",
    "dmap.fit(X_pcm_train)\n",
    "dmap = dmap.set_target_coords([1, 2])\n",
    "\n",
    "X_dmap_train = dmap.transform(X_pcm_train)\n",
    "X_dmap_test = dmap.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visually compare original mapping versus out-of-sample mapping\n",
    "\n",
    "The upper plot shows the embedding of the training data `fit` and the lower plot the embedding for out-of-sample points. We see that the colour regions match and call it a success. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embedding(X_dmap_train, y_train, images_train, title=\"training data\")\n",
    "plot_embedding(X_dmap_test, y_test, images_test, title=\"out-of-sample data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
