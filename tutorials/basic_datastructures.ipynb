{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data structures: PCManifold and TSCDataFrame\n",
    "\n",
    "This tutorial introduces the two **datafold** data structures (located in the package `pcfold`):  \n",
    "\n",
    "* `PCManifold` - point clouds on a manifold  \n",
    "* `TSCDataFrame` - time series collection  \n",
    "\n",
    "Both data structures are used internally in models and algorithms, but can also used on their own. For the case of `TSCDataFrame` it is also a required input type for models that built from time series data. Because both classes have base classes that are widely used in the scientific context of Python (`numpy.ndarray` and `pandas.DataFrame`) the handling is straight forward. We can refer to the documentation of the original packages and only highlight in what context the two data structures are useful.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "from scipy.sparse.linalg import lsqr\n",
    "\n",
    "\n",
    "# NOTE: make sure \"path/to/datafold\" is in sys.path or PYTHONPATH if not installed\n",
    "from datafold.pcfold import PCManifold, TSCDataFrame \n",
    "from datafold.pcfold.kernels import GaussianKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Point cloud on manifold (`PCManifold`)\n",
    "`PCManifold` subclasses `numpy.ndarray` and therefore inherits a rich set of functionality of the quasi-standard representation of numerical data in Python. The `PCManifold` restricts the general purpose of the base class array to a specific case\n",
    "\n",
    "* A technical requirement is that the point cloud must be numeric (i.e. no `object`, `str` etc.) and two-dimensional with samples in rows and features in columns. \n",
    "* A non-technical requirement is that the point cloud is (beliebed to be) sampled from a manifold. This means it has some geometrical structure and is not completely random.\n",
    "\n",
    "To showcase some of the functionality, we first generate a dataset on a \"swiss-roll manifold\" using a data generator from scikit-learn. Once we have the swiss-roll point cloud, we create an instance of `PCManifold` where we attach as new attributes to the array: \n",
    "\n",
    "1. A kernel (here `GaussianKernel`) that describes the locality between points. \n",
    "2. An (optional) `cut_off` distance value that controls a threshold, at which all kernel values are set to zero if the corresponding metric exeeds the cut-off. The parameter allows us to promote sparsity (and scale problems) by restricting the \"sphere of influence\" with respect to the metric (here the Euclidean distance in `GaussianKernel`).\n",
    "3. A distance backend to select an algorithm for computing the distance matrix with the specified metric in the kernel. The distance backend has to support the metric that is required in the kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, color = make_swiss_roll(n_samples=2000)\n",
    "\n",
    "pcm = PCManifold(X, kernel=GaussianKernel(epsilon=4), cut_off=6, dist_backend=\"guess_optimal\")\n",
    "\n",
    "# plot the swiss roll dataset\n",
    "fig = plt.figure(figsize=[7, 7])\n",
    "ax = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "ax.scatter(*X.T, c=color, cmap=plt.cm.Spectral)\n",
    "ax.set_title(\"Swiss roll: sampled manifold point cloud\");\n",
    "\n",
    "print(f\"isinstance(pcm, np.ndarray)={isinstance(pcm, np.ndarray)}\" )\n",
    "pcm  # displays the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showcase: Radial basis interpolation of swiss-roll with color as function target \n",
    "\n",
    "We can now use the `PCManifold` object to evaluate the attached kernel and compute the kernel matrix for the actual point cloud. Kernel matrices are used in many algorithms with \"manifold assumption\", because the kernel describes the local information of a point with respect to its neighborhood. We showcase this by creating an radial basis interpolation (RBF) and use the (extended) functionality of `PCManifold`. For simplicity we take the (pseudo-)color values of the swiss-roll data generator as the function target values that we want to interpolate. \n",
    "\n",
    "In the first step we compute the pairwise kernel matrix. With the kernel matrix and the known target values we compute the RBF weights by using a sparse least squares solver from the scipy package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use PCManifold to evaluate specified kernel on point cloud\n",
    "kernel_matrix = pcm.compute_kernel_matrix()  # returns a scipy.sparse.csr_matrix\n",
    "\n",
    "# compute RBF interpolation weights\n",
    "weights = lsqr(kernel_matrix, color)[0]\n",
    "color_rbf_centers = kernel_matrix @ weights\n",
    "\n",
    "# plotting:\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "ax.scatter(*X.T, c=color_rbf_centers, cmap=plt.cm.Spectral)\n",
    "ax.set_title(\"RBF interpolation at training points\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computed weights allow us to interpolate out-of-sample points with the RBF model. To actually interpolate points we generate a new set of points on the swiss-roll manifold, interpolate the color values and (visually) compare it with the true color information.  \n",
    "\n",
    "The out-of-sample point cloud are now a reference point cloud for the existing `PCManifold`. This means we compute the kernel matrix now component wise. Because we view the points independently for interpolation, we do not need to make new point cloud a `PCManifold`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create many out-of-sample points\n",
    "X_interp, true_color = make_swiss_roll(20000)\n",
    "\n",
    "# interpolate points with RBF model\n",
    "kernel_matrix_interp = pcm.compute_kernel_matrix(Y=X_interp)  # component wise if Y is not None\n",
    "color_rbf_interp = kernel_matrix_interp @ weights\n",
    "\n",
    "# plotting:\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1, projection=\"3d\")\n",
    "ax.scatter(*X_interp.T, c=true_color, cmap=plt.cm.Spectral)\n",
    "ax.set_title(\"True color values from swiss role\")\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2, projection=\"3d\")\n",
    "ax.scatter(*X_interp.T, c=color_rbf_interp, cmap=plt.cm.Spectral)\n",
    "ax.set_title(\"Interpolated color at interpolated points\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "In effectively 4 lines of code we created an RBF interpolation by using the `PCManifold` object. We can now easily exchange a kernel, compute a kernel matrix with varying degree of sparsity, and choose a distance algorithm (usually the computationally most expensive part). The data structure makes kernel based algorithms much easier to write and improves code readability.\n",
    "\n",
    "The RBF showcase can be improved by \n",
    "\n",
    "* properly optimizing the kernel parameters (see e.g. `PCManifold.optimize_parameters()` or via cross validation)\n",
    "* choose another interpolation method (e.g. `GeometricHarmonicsInterpolator`), as target values in regions with low sampling density quickly decrease to zero for RBF interpolation.\n",
    "\n",
    "Because `PCManifold` inherits from `numpy.ndarray`, we can use all of NumPy's functionality in-place. For example, we can compute eigenvectors on a `PCManifold` with \n",
    "\n",
    "```\n",
    "np.linalg.eig(pcm)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time series collection (`TSCDataFrame`)\n",
    "\n",
    "`TSCDataFrame` adds time context to sampled data coming from dynamical systems (e.g. either simulated from a ODE/PDE system or measured with a sensor). The data-driven models aiming to learn a dynamical system from data, (also known as [\"system identification\"](https://en.wikipedia.org/wiki/System_identification)) have, like in `PCManifold` often the assumption that the system's phase space lies on a manifold. However, in contrast to an unordered point cloud, time series data have an inherit temporal order and moreover may have come from different time series with different initial condition. These \"time issues\" require in many cases a separate handling, for example, if we randomly subsample time series without taking care of the time values, a desired property of having evenly sampled time values is destroyed.  \n",
    "\n",
    "To adress the special handling of time series collection data, we introduce the data structure `TSCDataFrame`. It subclasses from `pandas.DataFrame` and therefore inherits rich functionality from another popular Python package. \n",
    "\n",
    "\n",
    "To showcase `TSCDataFrame` we define a simple linear system to generate (single) time series data as a `pandas.DataFrame`. Note that data are the spatial positions and the index containts the time information). We can give the features (columns) names, in this case `x1` and `x2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "def get_data(t, x0) -> pd.DataFrame:\n",
    "    r\"\"\"Evaluate time series of randomly created linear system.\n",
    "    \n",
    "    Solves:\n",
    "    \n",
    "    .. code-block::\n",
    "        \n",
    "        dx/dt = A x\n",
    "        \n",
    "    where `A` is a random matrix. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    t \n",
    "        time values to evaluate\n",
    "    \n",
    "    x0\n",
    "        initial state (2-dimensional)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        time series with shape `(n_time_values, 2)`\n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.random.randn(2,2)\n",
    "    \n",
    "    expA = scipy.linalg.expm(A)\n",
    "    states = np.row_stack([scipy.linalg.fractional_matrix_power(expA, ti) @ x0 for ti in t])\n",
    "    \n",
    "    return pd.DataFrame(data=np.real(states), index=t, columns=['x1','x2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a TSCDataFrame\n",
    "\n",
    "Now that we have a way to generate individual time series, let us collect two of them into a `TSCDataFrame`. \n",
    "\n",
    "In general, we can create a new instance of `TSCDataFrame` like the super class\n",
    "\n",
    "```\n",
    "DataFrame(data, index, columns, **kwargs)` \n",
    "```\n",
    "\n",
    "However, at this stage the requirements on the frame format of a `TSCDataFrame` must be fulfilled already, which are:\n",
    "\n",
    "* Two levels of index, where the first index level is the time series ID and the second for the time values.\n",
    "* One level index for columns to index features.\n",
    "* The time series IDs must be positive integers, and the time values must be numeric. \n",
    "* Each time series must have at least two time values.\n",
    "* There are no duplicated indexes allowed (row and columns).\n",
    "\n",
    "Note that the data orientation is the same as in `PCManifold` (samples in rows, features in columns). \n",
    "\n",
    "For easier instantiation, there are also classmethods `TSCDataFrame.from_X`.  \n",
    "\n",
    "Here, we use `TSCDataFrame.from_single_timeseries`, where we only need to insert a single `pandas.DataFrame(data, index=time, columns=feature_names)`. After the initial construction we can iteratively add new time series with `tsc.insert_ts()`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a single time series as pandas data frame with time as index\n",
    "x0 = np.random.randn(2,)\n",
    "x1 = np.random.randn(2,)\n",
    "data1 = get_data(np.arange(0, 5), x0)\n",
    "data2 = get_data(np.arange(0, 5), x1)\n",
    "\n",
    "# convert it to a \"time series collection\" (TSC) data frame\n",
    "tsc_regular = TSCDataFrame.from_single_timeseries(data1)\n",
    "tsc_regular = tsc_regular.insert_ts(data2)  # here could be loop to insert more time series\n",
    "\n",
    "\n",
    "print('delta_time:', tsc_regular.delta_time)\n",
    "print('n_timesteps:', tsc_regular.n_timesteps)\n",
    "print('is_const_delta_time:', tsc_regular.is_const_delta_time())\n",
    "print('is_equal_length:', tsc_regular.is_equal_length())\n",
    "print('is_same_time_values:', tsc_regular.is_same_time_values())\n",
    "\n",
    "tsc_regular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a second `TSCDataFrame`, in which the time series are not sharing the same time values. For instatiation we use `TSCDataFrame.from_frame_list`, which allows a list of single time series (as `pandas.DataFrame`) to be inserted. \n",
    "\n",
    "We see that `delta_time` and `n_timesteps` cannot give a \"global\" value of the entire time series collection anymore. Instead the attributes list the value for each time series and is of type `pandas.Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = get_data(np.arange(0, 5), np.random.randn(2,))\n",
    "df2 = get_data(np.arange(5, 10, 2), np.random.randn(2,))\n",
    "\n",
    "tsc_irregular = TSCDataFrame.from_frame_list([df1, df2])\n",
    "\n",
    "print('delta_time:', tsc_irregular.delta_time)\n",
    "print('')\n",
    "print('n_timesteps:', tsc_irregular.n_timesteps)\n",
    "print('')\n",
    "print('is_const_delta_time:', tsc_irregular.is_const_delta_time())\n",
    "print('is_equal_length:', tsc_irregular.is_equal_length())\n",
    "print('is_same_time_values:', tsc_irregular.is_same_time_values())\n",
    "\n",
    "# print the time series. It now has two series in it, with IDs 0 and 1.\n",
    "tsc_irregular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing data\n",
    "\n",
    "Because `TSCDataFrame` is a `pandas.DataFrame` most of the data access and functions work in the same way. However, there are a few things to consider:\n",
    "\n",
    "* The `TSCDataFrame` type is kept as long as the accessed data slice is still valid (i.e. fulfills the format requirements). This is also true if the sliced data would  actually be a `Series` (but note last point).\n",
    "* If a slice leads to an invalid `TSCDataFrame`  then the general fallback type is `pandas.DataFrame` or `pandas.Series` (e.g. accessing a single row leads to an invalid time series collection, as more than one sample is required).\n",
    "* Currently, there are inconsistencies with pandas, because currently there is no \"`TSCSeries`\". This is most noteable for `.iloc` slicing which returns `pandas.Series` even if it is a valid `TSCDataFrame` (with one column). A simple type conversion `TSCDataFrame(slice_result)` is the current workaround.\n",
    "\n",
    "In the following we look at some examples to slice data from the constructed `tsc_regular` and `tsc_irregular`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access an individual feature from the collection\n",
    "\n",
    "Note that the type is now a `TSCDataFrame` and not a `pandas.Series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_result = tsc_regular[\"x1\"]\n",
    "\n",
    "print(type(slice_result))\n",
    "slice_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also always possible to turn the object to a `pandas.DataFrame` beforehand and have the usual accessing.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_result = pd.DataFrame(tsc_regular)[\"x1\"]\n",
    "\n",
    "print(type(slice_result))\n",
    "slice_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inconsistency with `.iloc` manifests as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_result = tsc_regular.iloc[:, 0]  # access the 0-th column\n",
    "\n",
    "print(type(slice_result))\n",
    "slice_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to recover `TSCDataFrame` type we can workaround:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_result = TSCDataFrame(tsc_regular.iloc[:, 0])\n",
    "\n",
    "print(type(slice_result))\n",
    "slice_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access a single time series\n",
    "\n",
    "A `TSCDataFrame` has a two level index, the first index the ID and the second the time. When we now access a single ID, the the now constant ID index is dropped. This means the returned slice is not a legal `TSCDataFrame` anymore and the type falls back to `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_result = tsc_regular.loc[0]\n",
    "\n",
    "print(type(slice_result))\n",
    "slice_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select specific time values\n",
    "\n",
    "The minimum length of a time series is two. If we request specific time values and all time series have more than one matching sample the type remains `TSCDataFrame`.   \n",
    "\n",
    "Also note that the inherited rules of accessing data from a pandas DataFrame hold. In the following example not all requested time values have to exist in all time series (not even in *any* as indicated with time value 99). An `KeyError` exception is only raised if *no* time value matches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_result = tsc_irregular.select_time_values([3, 4, 5, 7, 99])\n",
    "print(type(slice_result))\n",
    "slice_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_result = tsc_irregular.select_time_values(1)\n",
    "print(type(slice_result))\n",
    "slice_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting initial states\n",
    "\n",
    "Initial states are required for a dynamic model to make predictions and evolve the system forward in time. An initial condition can be either of a single state (typed as a `pandas.DataFrame`), but can also be a time series itself (e.g. the current state and the past samples). Extracting initial states work with the usual pandas slicing. Here we take the first sample by using the `groupby` function and take the first sample of each series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_result = tsc_regular.groupby('ID').head(1)\n",
    "print(type(slice_result))\n",
    "slice_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there is also a convenience function which improves code readability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_result = tsc_regular.initial_states()\n",
    "print(type(slice_result))\n",
    "slice_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take the first 2 samples. (Note that the times mismatch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_result = tsc_irregular.initial_states(2)\n",
    "print(type(slice_result))\n",
    "slice_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is actually an extra class `InitialCodition` that provides methods and validation for initial conditions. \n",
    "\n",
    "For example, we want to adress different situations:\n",
    "\n",
    "* In the case where time series have the same time values, we want to group and evaluate these initial conditions for these time values together.\n",
    "\n",
    "* If time series have different time values, we want to treat them separately and make separate predictions with the model.\n",
    "\n",
    "For example, this functionality is very useful when we want to reconstruct a time series data with a model. We use the iterator `InitialCondition.iter_reconstruct_ic` method:\n",
    "\n",
    "(Note that `InitialCondition.validate(ic)` can be used to check if the initial condition is valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datafold.pcfold import InitialCondition\n",
    "\n",
    "print(\"REGULAR CASE (groups time series together)\")\n",
    "print(\"------------------------------------------\\n\")\n",
    "\n",
    "for ic, time_values in InitialCondition.iter_reconstruct_ic(tsc_regular):\n",
    "    print(f\"Initial condition \\n\")\n",
    "    print(ic)\n",
    "    assert InitialCondition.validate(ic)\n",
    "    print(f\"with corresponding time values {time_values}\")\n",
    "\n",
    "    \n",
    "print(\"\\n\\n==========================================================================\\n\\n\")\n",
    "print(\"IRREGULAR CASE (separates initial conditions):\")\n",
    "print(\"----------------------------------------------\")\n",
    "\n",
    "for ic, time_values in InitialCondition.iter_reconstruct_ic(tsc_irregular):\n",
    "    print(f\"Initial condition \\n\")\n",
    "    print(ic)\n",
    "    assert InitialCondition.validate(ic)\n",
    "    print(f\"with corresponding time values {time_values}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot time series data\n",
    "\n",
    "`TSCDataFrame` provides basic plotting facility: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsc_regular.plot(figsize=(7,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the iterator `TSCDataFrmae.itertimeseries` which allows us access the time series separately and create plots for each time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, len(tsc_regular.ids),figsize=(15,7),sharey=True)\n",
    "\n",
    "for _id, time_series in tsc_regular.itertimeseries():\n",
    "    ts_axis = time_series.plot(ax=ax[_id])\n",
    "    ts_axis.set_title(f'time series ID={_id}')\n",
    "    if _id == 0:\n",
    "        ts_axis.set_ylabel('quantity of interest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
