{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data structures: PCManifold and TSCDataFrame\n",
    "\n",
    "This tutorial introduces the two data structures (in `datafold.pcfold`)\n",
    "\n",
    "* `PCManifold` - point clouds on a manifold  \n",
    "* `TSCDataFrame` - time series collection  \n",
    "\n",
    "Both data structures are used in internally in classes, but can also used on their own and sometimes are even required as input fomar (e.g. for time series predictions). Because both classes have widely used scientific computing base classes (`numpy.ndarray` and `pandas.DataFrame`) the handling is straight forward and we can also refer to existing documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "\n",
    "# NOTE: make sure \"path/to/datafold\" is in sys.path or PYTHONPATH if not installed\n",
    "from datafold.pcfold import PCManifold, TSCDataFrame \n",
    "from datafold.pcfold.kernels import GaussianKernel\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "\n",
    "from scipy.sparse.linalg import lsqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Point clouds on manifold (`PCManifold`)\n",
    "`PCManifold` subclasses `numpy.ndarray` and therefore inherits a rich set of functionality. A technical requirement to reduce the more general scope of the base class is that the point cloud (data array) must be numeric and two-dimensional with samples in rows and features in columns. The other non-technical requirement is that the point cloud is sampled from a manifold (i.e. has some structure and is not completely random).   \n",
    "\n",
    "To showcase some of the functionality, we first generate a point cloud dataset on a \"swiss-roll manifold\" using a dataset generator from scikit-learn. \n",
    "\n",
    "We create an instance of `PCManifold` by attaching\n",
    "\n",
    "1. a kernel (`GaussianKernel`) that describes locality on the manifold\n",
    "2. an optional `cut_off`, which promotes sparsity for kernel evaluations. It allows us to promote sparsity (and scale problems) and restrict the \"sphere of influence\" and with respect to the metric (here the Euclidean distance in `GaussianKernel`).\n",
    "3. a distance backend to select the algorithm for computing a distance matrix with the specified metric in the kernel \n",
    "\n",
    "to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, color = make_swiss_roll(n_samples=2000)\n",
    "\n",
    "pcm = PCManifold(X, kernel=GaussianKernel(epsilon=4), cut_off=6, dist_backend=\"guess_optimal\")\n",
    "\n",
    "fig = plt.figure(figsize=[7, 7])\n",
    "ax = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "ax.scatter(*X.T, c=color, cmap=plt.cm.Spectral)\n",
    "ax.set_title(\"Swiss roll: sampled manifold point cloud\");\n",
    "\n",
    "print(f\"isinstance(pcm, np.ndarray)={isinstance(pcm, np.ndarray)}\" )\n",
    "pcm  # displays the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showcase: Radial basis interpolation with targets=color\n",
    "\n",
    "We can now use the `PCManifold` object to evaluate the kernel and compute the kernel matrix, which consists of locality information of data points. Kernel matrices are used in many algorithms with \"manifold assumption\".\n",
    "\n",
    "We showcase this by creating an radial basis interpolation (RBF) and using the extended functionality of a `PCManifold`. For simplicity we take the (pseudo-)color values of the data generator as function target values. \n",
    "\n",
    "In the first step we compute the pairwise kernel matrix. With the kernel matrix and the known target values we compute the RBF weights and using a sparse least squares solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use PCManifold to evaluate specified kernel on point cloud\n",
    "kernel_matrix = pcm.compute_kernel_matrix()\n",
    "\n",
    "# compute RBF interpolation weights\n",
    "weights = lsqr(kernel_matrix, color)[0]\n",
    "color_rbf_centers = kernel_matrix @ weights\n",
    "\n",
    "# plotting:\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "ax.scatter(*X.T, c=color_rbf_centers, cmap=plt.cm.Spectral)\n",
    "ax.set_title(\"RBF interpolation model evaluated at known points\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computed weights allow us to interpolate out-of-sample points with the RBF model. For this, we generate more data on the S-curve manifold for a out-of-sample dataset and visually compare it with the true color information. \n",
    "\n",
    "The out-of-sample point cloud are reference points for the existing `PCManifold`. So we evaluate the same kernel again, but instead of a pairwise kernel matrix, we compute it component-wise with the out-of-sample point cloud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create out-of-sample points\n",
    "X_interp, true_color = make_swiss_roll(20000)\n",
    "\n",
    "# interpolate points with RBF model\n",
    "kernel_matrix_interp = pcm.compute_kernel_matrix(Y=X_interp)\n",
    "color_rbf_interp = kernel_matrix_interp @ weights\n",
    "\n",
    "# plotting:\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1, projection=\"3d\")\n",
    "ax.scatter(*X_interp.T, c=true_color, cmap=plt.cm.Spectral)\n",
    "ax.set_title(\"True color values from swiss role\")\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2, projection=\"3d\")\n",
    "ax.scatter(*X_interp.T, c=color_rbf_interp, cmap=plt.cm.Spectral)\n",
    "ax.set_title(\"Interpolated color at interpolated points\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The showcase be improved by \n",
    "\n",
    "* properly optimizing the kernel parameters (see e.g. `PCManifold.optimize_parameters()` or via cross validation)\n",
    "* choose another interpolation method (e.g. `GeometricHarmonicsInterpolator`), as target values in regions with low sampling density quickly decrease to zero for RBF interpolation.\n",
    "\n",
    "The key point is that that `PCManifold` provides ingredients to define a locality measure on manifolds via a kernel. We can simply evaluate a kernel matrix (both dense and sparse) of the existing point cloud or with respect to a reference point cloud.    \n",
    "\n",
    "Because it inherits from `numpy.ndarray`, we can use all the numpy functionality in-place. For example, we can compute eigenvectors on a `PCManifold` with \n",
    "\n",
    "```\n",
    "np.linalg.eig(pcm)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series collection (`TSCDataFrame`)\n",
    "\n",
    "This data structure adds time context to the collected data, specifically data coming from dynamical systems (either simulated or measured with a sensor). When learning a dynamical system from data, which is better known as [\"system identification\"](https://en.wikipedia.org/wiki/System_identification), also algorithms often have the assumption that the system's phase space lies on a manifold. In contrast to `PCManifold`, which looks at unordered point clouds, we want to address the temporal ordering. We also account for the fact that there can be one or many time series recorded that need to be looked at separately. These issues prohibit also operations on `PCManifold`, for example, if we subsample time series without taking care of time information, a desired property of having evenly sampled time values is destroyed.  \n",
    "\n",
    "To adress the special handling of time series data, we introduce the data structure `TSCDataFrame`. It subclasses from `pandas.DataFrame` and therefore inherits a different set of methods from a popular Python package. \n",
    "\n",
    "To showcase `TSCDataFrame` we define a simple linear system to generate (single) time series data as a `pandas.DataFrame`. Note that data are the spatial positions and the index containts the time information). We can give the features (columns) names, in this case `x1` and `x2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(t, x0) -> pd.DataFrame:\n",
    "    r\"\"\"Evaluate time series of randomly created linear system.\n",
    "    \n",
    "    Solves:\n",
    "    \n",
    "    .. code-block::\n",
    "        \n",
    "        dx/dt = A x\n",
    "        \n",
    "    where `A` is a random matrix. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    t \n",
    "        time values to evaluate\n",
    "    \n",
    "    x0\n",
    "        initial state (2-dimensional)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        time series with shape `(n_time_values, 2)`\n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.random.randn(2,2)\n",
    "    \n",
    "    expA = scipy.linalg.expm(A)\n",
    "    states = np.row_stack([scipy.linalg.fractional_matrix_power(expA, ti) @ x0 for ti in t])\n",
    "    \n",
    "    return pd.DataFrame(data=np.real(states), index=t, columns=['x1','x2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a TSCDataFrame\n",
    "\n",
    "Now that we have a way to generate individual time series, let us collect two of them into a time series collection (`TSCDataFrame`). \n",
    "\n",
    "In general, we can use the usual of `pandas.DataFrame(data, index, columns, **kwargs)`, however, the requirements on the frame format of a `TSCDataFrame` must be fulfilled already. For easier instantiation, there are classmethods `TSCDataFrame.from_X` that allow construction from common situations.\n",
    "\n",
    "Here, we use `TSCDataFrame.from_single_timeseries`, where we only need to insert a single `pandas.DataFrame(data, index=time, columns=feature_names)`. After the initial construction we can iteratively add new time series with `insert_ts()`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a single time series as pandas data frame with time as index\n",
    "x0 = np.random.randn(2,)\n",
    "x1 = np.random.randn(2,)\n",
    "data1 = get_data(np.arange(0, 5), x0)\n",
    "data2 = get_data(np.arange(0, 5), x1)\n",
    "\n",
    "# convert it to a \"time series collection\" (TSC) data frame\n",
    "tsc_regular = TSCDataFrame.from_single_timeseries(data1)\n",
    "tsc_regular = tsc_regular.insert_ts(data2)\n",
    "\n",
    "\n",
    "print('delta_time:', tsc_regular.delta_time)\n",
    "print('n_timesteps:', tsc_regular.n_timesteps)\n",
    "print('is_const_delta_time:', tsc_regular.is_const_delta_time())\n",
    "print('is_equal_length:', tsc_regular.is_equal_length())\n",
    "print('is_same_time_values:', tsc_regular.is_same_time_values())\n",
    "\n",
    "tsc_regular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create another `TSCDataFrame`, where now the time series do not share the same time values. This time we use `TSCDataFrame.from_frame_list` that allows to insert a list of data frames time series. \n",
    "\n",
    "We see that `delta_time` and `n_timesteps` cannot give a \"global\" of the entire time series colleciton anymore. Instead the attributes list the value for each timeseries ID typed with a `pandas.Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = get_data(np.arange(0, 5), np.random.randn(2,))\n",
    "df2 = get_data(np.arange(5, 10, 2), np.random.randn(2,))\n",
    "\n",
    "tsc_irregular = TSCDataFrame.from_frame_list([df1, df2])\n",
    "\n",
    "print('delta_time:', tsc_irregular.delta_time)\n",
    "print('')\n",
    "print('n_timesteps:', tsc_irregular.n_timesteps)\n",
    "print('')\n",
    "print('is_const_delta_time:', tsc_irregular.is_const_delta_time())\n",
    "print('is_equal_length:', tsc_irregular.is_equal_length())\n",
    "print('is_same_time_values:', tsc_irregular.is_same_time_values())\n",
    "\n",
    "# print the time series. It now has two series in it, with IDs 0 and 1.\n",
    "tsc_irregular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing time series data\n",
    "\n",
    "Because `TSCDataFrame` is a subclass of `pandas.DataFrame` many functions and attributes are inherited that can generally be used like on a normal `pandas.DataFrame`. However, there are things to consider:\n",
    "\n",
    "* The `TSCDataFrame` type is kept as long as the validation of being a legal format is successful. \n",
    "* If a slice leads to an invalid `TSCDataFrame` (e.g. talking a single row, as a time series must have more than one point), then the general fallback type is `pandas.DataFrame`.\n",
    "* Currently, there are inconsistencies with pandas, because there is currently no \"`TSCSeries`\". This is most noteable for `.iloc` slicing which returns `pandas.Series` even if is a valid `TSCDataFrame` (with one columns). A simple type conversion `TSCDataFrame(slice_result)` is the current workaround.\n",
    "\n",
    "In the following are some examples to access data using the constructed `tsc_regular` and `tsc_irregular`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access an individual coordinate with the times and IDs\n",
    "\n",
    "Note that the type is now a `TSCDataFrame` and not a `pandas.Series`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_result = tsc_regular[\"x1\"]\n",
    "\n",
    "print(type(slice_result))\n",
    "slice_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also always possible to turn the object to a `pandas.DataFrame` beforehand and have the usual accessing.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_result = pd.DataFrame(tsc_regular)[\"x1\"]\n",
    "\n",
    "print(type(slice_result))\n",
    "slice_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inconsistency with `.iloc` looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_result = tsc_regular.iloc[:, 0]\n",
    "\n",
    "print(type(slice_result))\n",
    "slice_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we require the type to be a `TSCDataFrame` we can workaround this with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_result = TSCDataFrame(tsc_regular.iloc[:, 0])\n",
    "\n",
    "print(type(slice_result))\n",
    "slice_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Access a single time series\n",
    "\n",
    "A `TSCDataFrame` has a two level index, the first index the ID and the second the time. When we now access a singe ID pandas drops the constant ID index. Because of this, a single accessed time series is not a valid `TSCDataFrame` anymore and falls back to `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_result = tsc_regular.loc[0]\n",
    "\n",
    "print(type(slice_result))\n",
    "slice_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select specific time values\n",
    "\n",
    "The minimum length of a time series is two. If we access specific time values, and a time series has only one matching time value the return type will be a `pandas.DataFrame`. \n",
    "\n",
    "In general, the typical rules of accessing data from a frame hold. In the following example not all requested time values have to exist in all time series (not even in *any* as indicated with time value 99). An `KeyError` exception is only raised if *no* time value matches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_result = tsc_irregular.select_time_values([3, 4, 5, 7, 99])\n",
    "print(type(slice_result))\n",
    "slice_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_result = tsc_irregular.select_time_values(1)\n",
    "print(type(slice_result))\n",
    "slice_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting initial states\n",
    "\n",
    "Initial states are required for a dynamic model to make predictions and evolve the system forward in time. An initial condition can be either of a single state (typed as a `pandas.DataFrame`), but can also be a time series itself (e.g. the current state and the past samples). Extracting initial states works with the usual pandas slicing. Here we take the first sample of each time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_result = tsc_regular.groupby('ID').head(1)\n",
    "print(type(slice_result))\n",
    "slice_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... but ther is also a convenience function and improves readability in the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_result = tsc_regular.initial_states(1)\n",
    "print(type(slice_result))\n",
    "slice_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take the first 2 samples. (Note that the times mismatch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_result = tsc_irregular.initial_states(2)\n",
    "print(type(slice_result))\n",
    "slice_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is actually an extra class `InitialCodition` that provides methods and validation for initial conditions. \n",
    "\n",
    "For example, we want to adress different situations:\n",
    "\n",
    "* In the case where time series have the same time values, we want to evaluate group them together. So we can give a model a set of initial conditions and evaluate each for the same time values. \n",
    "\n",
    "* If time series have different time values, we want to treat them separately and make separate model requests.\n",
    "\n",
    "This functionality is very useful if we want to reconstruct a time series data with a model. For this we can create an iterator with the `InitialCondition.iter_reconstruct_ic` method.\n",
    "\n",
    "Note that `InitialCondition.validate(ic)` can be used to check if the initial condition is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datafold.pcfold import InitialCondition\n",
    "\n",
    "print(\"REGULAR CASE (groups time series together)\")\n",
    "print(\"------------------------------------------\\n\")\n",
    "\n",
    "for ic, time_values in InitialCondition.iter_reconstruct_ic(tsc_regular):\n",
    "    print(f\"Initial condition \\n\")\n",
    "    print(ic)\n",
    "    assert InitialCondition.validate(ic)\n",
    "    print(f\"with corresponding time values {time_values}\")\n",
    "\n",
    "    \n",
    "print(\"\\n\\n==========================================================================\\n\\n\")\n",
    "print(\"IRREGULAR CASE (separates initial conditions):\")\n",
    "print(\"----------------------------------------------\")\n",
    "\n",
    "for ic, time_values in InitialCondition.iter_reconstruct_ic(tsc_irregular):\n",
    "    print(f\"Initial condition \\n\")\n",
    "    print(ic)\n",
    "    assert InitialCondition.validate(ic)\n",
    "    print(f\"with corresponding time values {time_values}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plotting time series data\n",
    "\n",
    "`TSCDataFrame` provides basic plotting facility: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsc_regular.plot(figsize=(7,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iterator `TSCDataFrmae.itertimeseries` allows to create separate plots for each time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, len(tsc_regular.ids),figsize=(15,7),sharey=True)\n",
    "\n",
    "for _id, time_series in tsc_regular.itertimeseries():\n",
    "    ts_axis = time_series.plot(ax=ax[_id])\n",
    "    ts_axis.set_title(f'time series ID={_id}')\n",
    "    if _id == 0:\n",
    "        ts_axis.set_ylabel('quantity of interest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
