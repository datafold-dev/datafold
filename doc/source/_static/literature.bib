
@article{le_clainche_higher_2017,
	title = {Higher order dynamic mode decomposition of noisy experimental data: {The} flow structure of a zero-net-mass-flux jet},
	volume = {88},
	issn = {08941777},
	shorttitle = {Higher order dynamic mode decomposition of noisy experimental data},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S089417771730184X},
	doi = {10.1016/j.expthermflusci.2017.06.011},
	abstract = {A method is presented to treat complex experimental flow data resulting from PIV. The method is based on an appropriate combination of higher order singular value decomposition (which cleans the data along the temporal dimension and the various space dimensions) and higher order dynamic mode decomposition (HODMD), a recent extension of standard dynamic mode decomposition that treats the data in a sliding window. The performance of the method is tested using experimental data obtained in the near field of a zero-net-mass-flux (ZNMF) jet. The better performance of HODMD is put in evidence making this technique suitable to both, cleaning the experimental noise using a limited number of snapshots and obtaining robust and sufficiently accurate results that elucidate the spatio-temporal structure of the flow. The results show that this ZNMF jet is temporally periodic in the near field, where the flow results from the interaction of a large number harmonics. These harmonics involve large scale spatial flow structures, identified as spatially growing instabilities, which are associated with the flow transition to turbulence in the far field.},
	language = {en},
	urldate = {2019-03-06},
	journal = {Experimental Thermal and Fluid Science},
	author = {Le Clainche, Soledad and Vega, Jos{\'e} M. and Soria, Julio},
	month = nov,
	year = {2017},
	pages = {336--353},
}

@article{berry_variable_2016,
	title = {Variable bandwidth diffusion kernels},
	volume = {40},
	issn = {10635203},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1063520315000020},
	doi = {10.1016/j.acha.2015.01.001},
	abstract = {Practical applications of kernel methods often use variable bandwidth kernels, also known as self-tuning kernels, however much of the current theory of kernel based techniques is only applicable to fixed bandwidth kernels. In this paper, we derive the asymptotic expansion of these variable bandwidth kernels for arbitrary bandwidth functions; generalizing the theory of Diffusion Maps and Laplacian Eigenmaps. We also derive pointwise error estimates for the corresponding discrete operators which are based on finite data sets; generalizing a result of Singer which was restricted to fixed bandwidth kernels. Our analysis reveals how areas of small sampling density lead to large errors, particularly for fixed bandwidth kernels. We explain the limitation of the existing theory to data sampled from compact manifolds by showing that when the sampling density is not bounded away from zero (which implies that the data lies on an open set) the error estimates for fixed bandwidth kernels will be unbounded. We show that this limitation can be overcome by choosing a bandwidth function inversely proportional to the sampling density (which can be estimated from data) which allows us to control the error estimates uniformly over a noncompact manifold. We numerically verify these results on non-compact manifolds by constructing the generator of the Ornstein{\textendash}Uhlenbeck process on a real line and a two-dimensional plane using data sampled independently from the respective invariant measures. We also verify our results on compact manifolds by constructing the Laplacian on the unit circle and the unit sphere and we show that the variable bandwidth kernels exhibit reduced sensitivity to bandwidth selection and give better results for an automatic bandwidth selection algorithm.},
	language = {en},
	number = {1},
	urldate = {2019-03-06},
	journal = {Applied and Computational Harmonic Analysis},
	author = {Berry, Tyrus and Harlim, John},
	month = jan,
	year = {2016},
	pages = {68--96},
}

@article{dsilva_parsimonious_2018,
	title = {Parsimonious representation of nonlinear dynamical systems through manifold learning: {A} chemotaxis case study},
	volume = {44},
	issn = {10635203},
	shorttitle = {Parsimonious representation of nonlinear dynamical systems through manifold learning},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1063520315000949},
	doi = {10.1016/j.acha.2015.06.008},
	abstract = {Nonlinear manifold learning algorithms, such as diffusion maps, have been fruitfully applied in recent years to the analysis of large and complex data sets. However, such algorithms still encounter challenges when faced with real data. One such challenge is the existence of {\textquotedblleft}repeated eigendirections,{\textquotedblright} which obscures the detection of the true dimensionality of the underlying manifold and arises when several embedding coordinates parametrize the same direction in the intrinsic geometry of the data set. We propose an algorithm, based on local linear regression, to automatically detect coordinates corresponding to repeated eigendirections. We construct a more parsimonious embedding using only the eigenvectors corresponding to unique eigendirections, and we show that this reduced diffusion maps embedding induces a metric which is equivalent to the standard diffusion distance. We first demonstrate the utility and flexibility of our approach on synthetic data sets. We then apply our algorithm to data collected from a stochastic model of cellular chemotaxis, where our approach for factoring out repeated eigendirections allows us to detect changes in dynamical behavior and the underlying intrinsic system dimensionality directly from data.},
	language = {en},
	number = {3},
	urldate = {2019-03-06},
	journal = {Applied and Computational Harmonic Analysis},
	author = {Dsilva, Carmeline J. and Talmon, Ronen and Coifman, Ronald R. and Kevrekidis, Ioannis G.},
	month = may,
	year = {2018},
	pages = {759--773},
}

@article{champion_discovery_2019,
	title = {Discovery of {Nonlinear} {Multiscale} {Systems}: {Sampling} {Strategies} and {Embeddings}},
	volume = {18},
	issn = {1536-0040},
	shorttitle = {Discovery of {Nonlinear} {Multiscale} {Systems}},
	url = {https://epubs.siam.org/doi/10.1137/18M1188227},
	doi = {10.1137/18M1188227},
	abstract = {A major challenge in the study of dynamical systems is that of model discovery: turning data into models that are not just predictive, but provide insight into the nature of the underlying dynamical system that generated the data. This problem is made more difficult by the fact that many systems of interest exhibit diverse behaviors across multiple time scales. We introduce a number of datadriven strategies for discovering nonlinear multiscale dynamical systems and their embeddings from data. We consider two canonical cases: (i) systems for which we have full measurements of the governing variables and (ii) systems for which we have incomplete measurements. For systems with full state measurements, we show that the recent sparse identification of nonlinear dynamical systems (SINDy) method can discover governing equations with relatively little data, provided that accurate measurements of the derivatives can be computed from the data. We introduce a sampling method that allows SINDy to scale efficiently to problems with multiple time scales; specifically, we can discover distinct governing equations at slow and fast scales. For systems with incomplete observations, we show that the Hankel alternative view of Koopman (HAVOK) method, based on time-delay embedding coordinates, can be used to obtain a linear model and Koopman invariant measurement system that nearly perfectly captures the dynamics of nonlinear quasiperiodic systems on the attractor. We introduce two strategies for using HAVOK on systems with multiple time scales. Together, our approaches provide a suite of mathematical strategies for reducing the data required to discover and model nonlinear multiscale systems.},
	language = {en},
	number = {1},
	urldate = {2019-03-06},
	journal = {SIAM Journal on Applied Dynamical Systems},
	author = {Champion, Kathleen P. and Brunton, Steven L. and Kutz, J. Nathan},
	month = jan,
	year = {2019},
	pages = {312--333},
}

@article{tu_dynamic_2014,
	title = {On {Dynamic} {Mode} {Decomposition}: {Theory} and {Applications}},
	volume = {1},
	issn = {2158-2491},
	shorttitle = {On {Dynamic} {Mode} {Decomposition}},
	url = {http://arxiv.org/abs/1312.0041},
	doi = {10.3934/jcd.2014.1.391},
	abstract = {Originally introduced in the fluid mechanics community, dynamic mode decomposition (DMD) has emerged as a powerful tool for analyzing the dynamics of nonlinear systems. However, existing DMD theory deals primarily with sequential time series for which the measurement dimension is much larger than the number of measurements taken. We present a theoretical framework in which we define DMD as the eigendecomposition of an approximating linear operator. This generalizes DMD to a larger class of datasets, including nonsequential time series. We demonstrate the utility of this approach by presenting novel sampling strategies that increase computational efficiency and mitigate the effects of noise, respectively. We also introduce the concept of linear consistency, which helps explain the potential pitfalls of applying DMD to rank-deficient datasets, illustrating with examples. Such computations are not considered in the existing literature, but can be understood using our more general framework. In addition, we show that our theory strengthens the connections between DMD and Koopman operator theory. It also establishes connections between DMD and other techniques, including the eigensystem realization algorithm (ERA), a system identification method, and linear inverse modeling (LIM), a method from climate science. We show that under certain conditions, DMD is equivalent to LIM.},
	language = {en},
	number = {2},
	urldate = {2019-03-06},
	journal = {Journal of Computational Dynamics},
	author = {Tu, Jonathan H. and Rowley, Clarence W. and Luchtenburg, Dirk M. and Brunton, Steven L. and Kutz, J. Nathan},
	month = dec,
	year = {2014},
	note = {arXiv: 1312.0041},
	keywords = {koopman},
	pages = {391--421},
}

@article{williams_datadriven_2015,
	title = {A {Data}{\textendash}{Driven} {Approximation} of the {Koopman} {Operator}: {Extending} {Dynamic} {Mode} {Decomposition}},
	volume = {25},
	issn = {0938-8974, 1432-1467},
	shorttitle = {A {Data}{\textendash}{Driven} {Approximation} of the {Koopman} {Operator}},
	url = {http://link.springer.com/10.1007/s00332-015-9258-5},
	doi = {10.1007/s00332-015-9258-5},
	language = {en},
	number = {6},
	urldate = {2019-03-13},
	journal = {Journal of Nonlinear Science},
	author = {Williams, Matthew O. and Kevrekidis, Ioannis G. and Rowley, Clarence W.},
	month = dec,
	year = {2015},
	pages = {1307--1346},
}

@phdthesis{lafon_diffusion_2004,
	title = {Diffusion {Maps} and {Geometric} {Harmonics}},
	language = {en},
	school = {Yale University},
	author = {Lafon, St{\'e}phane S},
	year = {2004},
}

@article{giannakis_data-driven_2019,
	title = {Data-driven spectral decomposition and forecasting of ergodic dynamical systems},
	volume = {47},
	issn = {10635203},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1063520317300982},
	doi = {10.1016/j.acha.2017.09.001},
	abstract = {We develop a framework for dimension reduction, mode decomposition, and nonparametric forecasting of data generated by ergodic dynamical systems. This framework is based on a representation of the Koopman and Perron{\textendash}Frobenius groups of unitary operators in a smooth orthonormal basis of the L2 space of the dynamical system, acquired from time-ordered data through the diffusion maps algorithm. Using this representation, we compute Koopman eigenfunctions through a regularized advection{\textendash}diffusion operator, and employ these eigenfunctions in dimension reduction maps with projectible dynamics and high smoothness for the given observation modality. In systems with pure point spectra, we construct a decomposition of the generator of the Koopman group into mutually commuting vector fields that transform naturally under changes of observation modality, which we reconstruct in data space through a representation of the pushforward map in the Koopman eigenfunction basis. We also establish a correspondence between Koopman operators and Laplace{\textendash}Beltrami operators constructed from data in Takens delaycoordinate space, and use this correspondence to provide an interpretation of diffusion-mapped delay coordinates for this class of systems. Moreover, we take advantage of a special property of the Koopman eigenfunction basis, namely that the basis elements evolve as simple harmonic oscillators, to build nonparametric forecast models for probability densities and observables. In systems with more complex spectral behavior, including mixing systems, we develop a method inspired from time change in dynamical systems to transform the generator to a new operator with potentially improved spectral properties, and use that operator for vector field decomposition and nonparametric forecasting.},
	language = {en},
	number = {2},
	urldate = {2019-12-14},
	journal = {Applied and Computational Harmonic Analysis},
	author = {Giannakis, Dimitrios},
	month = sep,
	year = {2019},
	pages = {338--396},
}

@article{berry_time-scale_2013,
	title = {Time-{Scale} {Separation} from {Diffusion}-{Mapped} {Delay} {Coordinates}},
	volume = {12},
	issn = {1536-0040},
	url = {http://epubs.siam.org/doi/10.1137/12088183X},
	doi = {10.1137/12088183X},
	abstract = {It has long been known that the method of time-delay embedding can be used to reconstruct nonlinear dynamics from time series data. A less-appreciated fact is that the induced geometry of time-delay coordinates increasingly biases the reconstruction toward the stable directions as delays are added. This bias can be exploited, using the diffusion maps approach to dimension reduction, to extract dynamics on desired time scales from high-dimensional observed data. We demonstrate the technique on a wide range of examples, including data generated by a model of meandering spiral waves and video recordings of a liquid-crystal experiment.},
	language = {en},
	number = {2},
	urldate = {2019-12-14},
	journal = {SIAM Journal on Applied Dynamical Systems},
	author = {Berry, T. and Cressman, J. R. and Greguri{\'c}-Feren{\v c}ek, Z. and Sauer, T.},
	month = jan,
	year = {2013},
	pages = {618--649},
}

@article{fernandez_diffusion_2015,
	title = {Diffusion {Maps} for dimensionality reduction and visualization of meteorological data},
	volume = {163},
	issn = {09252312},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231215004257},
	doi = {10.1016/j.neucom.2014.08.090},
	abstract = {The growing interest in big data problems implies the need for unsupervised methods for data visualization and dimensionality reduction. Diffusion Maps (DM) is a recent technique that can capture the lower dimensional geometric structure underlying the sample patterns in a way which can be made to be independent of the sampling distribution. Moreover, DM allows to define an embedding whose Euclidean metric relates to the sample{\textquoteright}s intrinsic one which, in turn, enables a principled application of k-means clustering. In this work we give a self-contained review of DM and discuss two methods to compute the DM embedding coordinates to new out-of-sample data. Then, we will apply them on two meteorological data problems that involve respectively time and spatial compression of numerical weather forecasts and show how DM is capable to, first, greatly reduce the initial dimension while still capturing relevant information in the original data and, also, how the sample-derived DM embedding coordinates can be extended to new patterns.},
	language = {en},
	urldate = {2019-12-14},
	journal = {Neurocomputing},
	author = {Fern{\'a}ndez, {\'A}ngela and Gonz{\'a}lez, Ana M. and D{\'i}az, Julia and Dorronsoro, Jos{\'e} R.},
	month = sep,
	year = {2015},
	pages = {25--37},
}

@article{chiavazzo_reduced_2014,
	title = {Reduced {Models} in {Chemical} {Kinetics} via {Nonlinear} {Data}-{Mining}},
	volume = {2},
	issn = {2227-9717},
	url = {http://www.mdpi.com/2227-9717/2/1/112},
	doi = {10.3390/pr2010112},
	language = {en},
	number = {1},
	urldate = {2019-12-14},
	journal = {Processes},
	author = {Chiavazzo, Eliodoro and Gear, Charles and Dsilva, Carmeline and Rabin, Neta and Kevrekidis, Ioannis},
	month = jan,
	year = {2014},
	pages = {112--140},
}

@inproceedings{rabin_heterogeneous_2012,
	title = {Heterogeneous datasets representation and learning using diffusion maps and {Laplacian} pyramids},
	isbn = {978-1-61197-232-0 978-1-61197-282-5},
	url = {https://epubs.siam.org/doi/10.1137/1.9781611972825.17},
	doi = {10.1137/1.9781611972825.17},
	abstract = {The diffusion maps together with the geometric harmonics provide a method for describing the geometry of high dimensional data and for extending these descriptions to new data points and to functions, which are defined on the data. This method suffers from two limitations. First, even though real-life data is often heterogeneous , the assumption in diffusion maps is that the attributes of the processed dataset are comparable. Second, application of the geometric harmonics requires careful setting for the correct extension scale and condition number. In this paper, we propose a method for representing and learning heterogeneous datasets by using diffusion maps for unifying and embedding heterogeneous dataset and by replacing the geometric harmonics with the Laplacian pyramid extension. Experimental results on three benchmark datasets demonstrate how the learning process becomes straightforward when the constructed representation smoothly parameterizes the task-related function.},
	language = {en},
	urldate = {2019-12-14},
	booktitle = {Proceedings of the 2012 {SIAM} {International} {Conference} on {Data} {Mining}},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Rabin, Neta and Coifman, Ronald R.},
	month = apr,
	year = {2012},
	pages = {189--199},
}

@article{coifman_geometric_2006,
	title = {Geometric harmonics: {A} novel tool for multiscale out-of-sample extension of empirical functions},
	volume = {21},
	issn = {10635203},
	shorttitle = {Geometric harmonics},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1063520306000522},
	doi = {10.1016/j.acha.2005.07.005},
	abstract = {We describe a simple scheme, based on the Nystr{\"o}m method, for extending empirical functions f defined on a set X to a larger set X{\textasciimacron} . The extension process that we describe involves the construction of a specific family of functions that we term geometric harmonics. These functions constitute a generalization of the prolate spheroidal wave functions of Slepian in the sense that they are optimally concentrated on X. We study the case when X is a submanifold of Rn in greater detail. In this situation, any empirical function f on X can be characterized by its decomposition over the intrinsic Fourier modes, i.e., the eigenfunctions of the Laplace{\textendash}Beltrami operator, and we show that this intrinsic frequency spectrum determines the largest domain of extension of f to the entire space Rn. Our analysis relates the complexity of the function on the training set to the scale of extension off this set. This approach allows us to present a novel multiscale extension scheme for empirical functions.},
	language = {en},
	number = {1},
	urldate = {2019-12-15},
	journal = {Applied and Computational Harmonic Analysis},
	author = {Coifman, Ronald R. and Lafon, St{\'e}phane},
	month = jul,
	year = {2006},
	pages = {31--52},
}

@article{coifman_diffusion_2006,
	title = {Diffusion maps},
	volume = {21},
	issn = {10635203},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1063520306000546},
	doi = {10.1016/j.acha.2006.04.006},
	abstract = {In this paper, we provide a framework based upon diffusion processes for finding meaningful geometric descriptions of data sets. We show that eigenfunctions of Markov matrices can be used to construct coordinates called diffusion maps that generate efficient representations of complex geometric structures. The associated family of diffusion distances, obtained by iterating the Markov matrix, defines multiscale geometries that prove to be useful in the context of data parametrization and dimensionality reduction. The proposed framework relates the spectral properties of Markov processes to their geometric counterparts and it unifies ideas arising in a variety of contexts such as machine learning, spectral graph theory and eigenmap methods.},
	language = {en},
	number = {1},
	urldate = {2019-12-15},
	journal = {Applied and Computational Harmonic Analysis},
	author = {Coifman, Ronald R. and Lafon, St{\'e}phane},
	month = jul,
	year = {2006},
	pages = {5--30},
}

@article{bengio_learning_2004,
	title = {Learning {Eigenfunctions} {Links} {Spectral} {Embedding} and {Kernel} {PCA}},
	volume = {16},
	issn = {0899-7667, 1530-888X},
	url = {http://www.mitpressjournals.org/doi/10.1162/0899766041732396},
	doi = {10.1162/0899766041732396},
	abstract = {In this paper, we show a direct relation between spectral embedding methods and kernel PCA, and how both are special cases of a more general learning problem, that of learning the principal eigenfunctions of an operator defined from a kernel and the unknown data generating density.},
	language = {en},
	number = {10},
	urldate = {2019-12-15},
	journal = {Neural Computation},
	author = {Bengio, Yoshua and Delalleau, Olivier and Roux, Nicolas Le and Paiement, Jean-Fran{\c c}ois and Vincent, Pascal and Ouimet, Marie},
	month = oct,
	year = {2004},
	pages = {2197--2219},
}

@article{fernandez_auto-adaptative_2014,
	title = {Auto-adaptative {Laplacian} {Pyramids} for {High}-dimensional {Data} {Analysis}},
	url = {http://arxiv.org/abs/1311.6594},
	abstract = {Non-linear dimensionality reduction techniques such as manifold learning algorithms have become a common way for processing and analyzing high-dimensional patterns that often have attached a target that corresponds to the value of an unknown function. Their application to new points consists in two steps: first, embedding the new data point into the low dimensional space and then, estimating the function value on the test point from its neighbors in the embedded space.},
	language = {en},
	urldate = {2019-12-22},
	journal = {arXiv:1311.6594 [cs, stat]},
	author = {Fern{\'a}ndez, {\'A}ngela and Rabin, Neta and Fishelov, Dalia and Dorronsoro, Jos{\'e} R.},
	month = may,
	year = {2014},
	note = {arXiv: 1311.6594},
}

@article{berry_consistent_2019,
	title = {Consistent {Manifold} {Representation} for {Topological} {Data} {Analysis}},
	url = {http://arxiv.org/abs/1606.02353},
	abstract = {For data sampled from an arbitrary density on a manifold embedded in Euclidean space, the Continuous k-Nearest Neighbors (CkNN) graph construction is introduced. It is shown that CkNN is geometrically consistent in the sense that under certain conditions, the unnormalized graph Laplacian converges to the Laplace-Beltrami operator, spectrally as well as pointwise. It is proved for compact (and conjectured for noncompact) manifolds that CkNN is the unique unweighted construction that yields a geometry consistent with the connected components of the underlying manifold in the limit of large data. Thus CkNN produces a single graph that captures all topological features simultaneously, in contrast to persistent homology, which represents each homology generator at a separate scale. As applications we derive a new fast clustering algorithm and a method to identify patterns in natural images topologically. Finally, we conjecture that CkNN is topologically consistent, meaning that the homology of the Vietoris-Rips complex (implied by the graph Laplacian) converges to the homology of the underlying manifold (implied by the Laplace-de Rham operators) in the limit of large data.},
	language = {en},
	urldate = {2020-01-02},
	journal = {arXiv:1606.02353 [math]},
	author = {Berry, Tyrus and Sauer, Timothy},
	month = feb,
	year = {2019},
	note = {arXiv: 1606.02353},
}

@article{berry_nonparametric_2015,
	title = {Nonparametric {Uncertainty} {Quantification} for {Stochastic} {Gradient} {Flows}},
	url = {http://arxiv.org/abs/1407.6972},
	abstract = {This paper presents a nonparametric statistical modeling method for quantifying uncertainty in stochastic gradient systems with isotropic diffusion. The central idea is to apply the diffusion maps algorithm to a training data set to produce a stochastic matrix whose generator is a discrete approximation to the backward Kolmogorov operator of the underlying dynamics. The eigenvectors of this stochastic matrix, which we will refer to as the diffusion coordinates, are discrete approximations to the eigenfunctions of the Kolmogorov operator and form an orthonormal basis for functions defined on the data set. Using this basis, we consider the projection of three uncertainty quantification (UQ) problems (prediction, filtering, and response) into the diffusion coordinates. In these coordinates, the nonlinear prediction and response problems reduce to solving systems of infinite-dimensional linear ordinary differential equations. Similarly, the continuous-time nonlinear filtering problem reduces to solving a system of infinite-dimensional linear stochastic differential equations. Solving the UQ problems then reduces to solving the corresponding truncated linear systems in finitely many diffusion coordinates. By solving these systems we give a model-free algorithm for UQ on gradient flow systems with isotropic diffusion. We numerically verify these algorithms on a 1-dimensional linear gradient flow system where the analytic solutions of the UQ problems are known. We also apply the algorithm to a chaotically forced nonlinear gradient flow system which is known to be well approximated as a stochastically forced gradient flow.},
	language = {en},
	urldate = {2020-01-06},
	journal = {arXiv:1407.6972 [math]},
	author = {Berry, Tyrus and Harlim, John},
	month = feb,
	year = {2015},
	note = {arXiv: 1407.6972},
}

@book{kutz_dynamic_2016,
	title = {Dynamic mode decomposition. {Data}-{Driven} modelling of complex systems},
	isbn = {978-1-61197-450-8},
	language = {en},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Kutz, J. Nathan and Brunton, Steven L. and Brunton, Bingni W. and Proctor, Joshua L.},
	year = {2016},
}

@article{schmid_dynamic_2010,
	title = {Dynamic mode decomposition of numerical and experimental data},
	volume = {656},
	issn = {0022-1120, 1469-7645},
	url = {https://www.cambridge.org/core/product/identifier/S0022112010001217/type/journal_article},
	doi = {10.1017/S0022112010001217},
	abstract = {The description of coherent features of fluid flow is essential to our understanding of fluid-dynamical and transport processes. A method is introduced that is able to extract dynamic information from flow fields that are either generated by a (direct) numerical simulation or visualized/measured in a physical experiment. The extracted dynamic modes, which can be interpreted as a generalization of global stability modes, can be used to describe the underlying physical mechanisms captured in the data sequence or to project large-scale problems onto a dynamical system of significantly fewer degrees of freedom. The concentration on subdomains of the flow field where relevant dynamics is expected allows the dissection of a complex flow into regions of localized instability phenomena and further illustrates the flexibility of the method, as does the description of the dynamics within a spatial framework. Demonstrations of the method are presented consisting of a plane channel flow, flow over a two-dimensional cavity, wake flow behind a flexible membrane and a jet passing between two cylinders.},
	language = {en},
	urldate = {2020-04-09},
	journal = {Journal of Fluid Mechanics},
	author = {Schmid, Peter J.},
	month = aug,
	year = {2010},
	pages = {5--28},
}

@article{belkin_laplacian_2003,
	title = {Laplacian {Eigenmaps} for {Dimensionality} {Reduction} and {Data} {Representation}},
	volume = {15},
	issn = {0899-7667, 1530-888X},
	url = {http://www.mitpressjournals.org/doi/10.1162/089976603321780317},
	doi = {10.1162/089976603321780317},
	language = {en},
	number = {6},
	urldate = {2020-04-29},
	journal = {Neural Computation},
	author = {Belkin, Mikhail and Niyogi, Partha},
	month = jun,
	year = {2003},
	pages = {1373--1396},
}

@article{donoho_hessian_2003,
	title = {Hessian eigenmaps: {Locally} linear embedding techniques for high-dimensional data},
	volume = {100},
	issn = {0027-8424, 1091-6490},
	shorttitle = {Hessian eigenmaps},
	url = {http://www.pnas.org/cgi/doi/10.1073/pnas.1031596100},
	doi = {10.1073/pnas.1031596100},
	language = {en},
	number = {10},
	urldate = {2020-04-29},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Donoho, D. L. and Grimes, C.},
	month = may,
	year = {2003},
	pages = {5591--5596},
}

@incollection{rand_detecting_1981,
	address = {Berlin, Heidelberg},
	title = {Detecting strange attractors in turbulence},
	volume = {898},
	isbn = {978-3-540-11171-9 978-3-540-38945-3},
	url = {http://link.springer.com/10.1007/BFb0091924},
	language = {en},
	urldate = {2020-04-29},
	booktitle = {Dynamical {Systems} and {Turbulence}, {Warwick} 1980},
	publisher = {Springer Berlin Heidelberg},
	author = {Takens, Floris},
	editor = {Rand, David and Young, Lai-Sang},
	year = {1981},
	doi = {10.1007/BFb0091924},
	note = {Series Title: Lecture Notes in Mathematics},
	pages = {366--381},
}

@book{bishop_pattern_2006,
	address = {New York},
	series = {Information science and statistics},
	title = {Pattern recognition and machine learning},
	isbn = {978-0-387-31073-2},
	language = {en},
	publisher = {Springer},
	author = {Bishop, Christopher M.},
	year = {2006},
	keywords = {Machine learning, Pattern perception},
}

@article{pedregosa_scikit-learn_2011,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
	abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
	language = {en},
	journal = {MACHINE LEARNING IN PYTHON},
	author = {Pedregosa, Fabian and Varoquaux, Gael and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David},
	year = {2011},
	pages = {6},
}

@article{brunton_discovering_2016,
	title = {Discovering governing equations from data by sparse identification of nonlinear dynamical systems},
	volume = {113},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1517384113},
	doi = {10.1073/pnas.1517384113},
	abstract = {Extracting governing equations from data is a central challenge in many diverse areas of science and engineering. Data are abundant whereas models often remain elusive, as in climate science, neuroscience, ecology, finance, and epidemiology, to name only a few examples. In this work, we combine sparsity-promoting techniques and machine learning with nonlinear dynamical systems to discover governing equations from noisy measurement data. The only assumption about the structure of the model is that there are only a few important terms that govern the dynamics, so that the equations are sparse in the space of possible functions; this assumption holds for many physical systems in an appropriate basis. In particular, we use sparse regression to determine the fewest terms in the dynamic governing equations required to accurately represent the data. This results in parsimonious models that balance accuracy with model complexity to avoid overfitting. We demonstrate the algorithm on a wide range of problems, from simple canonical systems, including linear and nonlinear oscillators and the chaotic Lorenz system, to the fluid vortex shedding behind an obstacle. The fluid example illustrates the ability of this method to discover the underlying dynamics of a system that took experts in the community nearly 30 years to resolve. We also show that this method generalizes to parameterized systems and systems that are time-varying or have external forcing.},
	language = {en},
	number = {15},
	urldate = {2020-04-29},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Brunton, Steven L. and Proctor, Joshua L. and Kutz, J. Nathan},
	month = apr,
	year = {2016},
	pages = {3932--3937},
}
