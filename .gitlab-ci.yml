stages:
  - remote_setup
  - test
  - code_analysis
  - deploy

variables:
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  PRE_COMMIT_DIR: "${CI_PROJECT_DIR}/.cache/pre-commit"
  VENV_DIR: "${CI_PROJECT_DIR}/venv"

cache:
  paths:
    - ${PIP_CACHE_DIR}
    - ${PRE_COMMIT_DIR}
    - ${VENV_DIR}

# https://gitlab.com/gitlab-org/gitlab/-/issues/33694#note_335120563
workflow:
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: never
    - when: always


# See keyword reference for the .gitlab-ci.yml file
# https://docs.gitlab.com/ee/ci/yaml/


setup:
  stage: remote_setup
  script:
    - virtualenv venv -p ~/Python-3.7.9/python
    - source venv/bin/activate
    - python -V
    - python -m pip install --upgrade pip
    - python -m pip install --upgrade setuptools
    - python -m pip install --upgrade twine
    - python -m pip install -r requirements-dev.txt


unittests:
  stage: test
  before_script:
    - source venv/bin/activate
    - python -V
  script:
    - python -m coverage run -m pytest datafold/
    - python -m coverage html -d ./coverage/
    - python -m coverage report
  allow_failure: false
  artifacts:
    paths:
      - ./coverage/
    expire_in: 1 week
    when: on_success
  interruptible: true

functional_tests:
  before_script:
    - source venv/bin/activate
    - python -V
  script:
    - export PYTHONPATH=`pwd`
    - echo $PYTHONPATH
    - python -m pytest tutorials/
  allow_failure: false
  interruptible: true


code_checks:
  stage: code_analysis
  before_script:
    - source venv/bin/activate
    - python -V
  script:
    - pre-commit run --all
  allow_failure: true
  interruptible: true


docu_check:
  stage: code_analysis
  before_script:
    - source venv/bin/activate
    - python -V
  script:
    - cd doc/ && make html
  except:
    - master
  allow_failure: false
  interruptible: true


pages:
  stage: deploy
  before_script:
    - source venv/bin/activate
    - python -V
  script:
    - export DATAFOLD_NBSPHINX_EXECUTE=always
    - sphinx-apidoc -f -o ./doc/source/_apidoc/ ./datafold/
    - sphinx-build -b html ./doc/source/ ./public/
  artifacts:
    paths:
    - public
  rules:
    # from: https://forum.gitlab.com/t/how-to-setup-manual-job-from-feature-branch-that-runs-automatically-on-master/38892
    # always update pages if on master
    - if: $CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH
      when: always
    # manual option if push to branches other than master
    - if: $CI_COMMIT_BRANCH != $CI_DEFAULT_BRANCH
      when: manual
      allow_failure: true


# For infos of testPyPI see here: https://packaging.python.org/guides/using-testpypi/
# Note that
#  "The database for TestPyPI may be periodically pruned, so it is not unusual for user
#   accounts to be deleted." -- it is best to use the same account and password as for
#   the real PyPI, so that the TWINE variables (see below) can be re-used
pypi_upload_test:  # uploads to test.pypi.org to see how everything renders
  stage: deploy
  before_script:
    - source venv/bin/activate
  script:
    - python setup.py sdist bdist_wheel
    - python -m twine check dist/*
    - python -m twine upload --verbose --repository testpypi dist/*
  when: manual

# Requires to set the variables TWINE_USERNAME and TWINE_PASSWORD in gitlab CI/CD
pypi_upload:
  stage: deploy
  before_script:
    - source venv/bin/activate
  script:
    - python setup.py sdist bdist_wheel
    - python -m twine check dist/*
    - python -m twine upload --verbose dist/*
  only:
    - master
  when: manual
